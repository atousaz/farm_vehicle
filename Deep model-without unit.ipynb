{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 14:56:53.066964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/atousaz/.local/lib/python3.9/site-packages/astroML/linear_model/linear_regression_errors.py:10: UserWarning: LinearRegressionwithErrors requires PyMC3 to be installed\n",
      "  warnings.warn('LinearRegressionwithErrors requires PyMC3 to be installed')\n"
     ]
    }
   ],
   "source": [
    "# Importing related packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.font_manager as font_manager\n",
    "from scipy.stats import iqr\n",
    "import math\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "\n",
    "fontname = 'Times New Roman'\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dataset\n",
    "car_df = pd.read_csv('deep_data_final_car.csv')\n",
    "truck_df = pd.read_csv('deep_data_final_truck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refining data\n",
    "car_df = car_df[['H', 'W', 'C_x', 'C_y', 'gps_dist', 'vehicle']]\n",
    "truck_df = truck_df[['H', 'W', 'C_x', 'C_y', 'gps_dist',  'vehicle']]\n",
    "df = pd.concat([car_df, truck_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>C_x</th>\n",
       "      <th>C_y</th>\n",
       "      <th>gps_dist</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185</td>\n",
       "      <td>286</td>\n",
       "      <td>303.0</td>\n",
       "      <td>444.5</td>\n",
       "      <td>7.507966</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>286</td>\n",
       "      <td>303.0</td>\n",
       "      <td>441.5</td>\n",
       "      <td>7.507966</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>280</td>\n",
       "      <td>302.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>7.507966</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>266</td>\n",
       "      <td>309.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>7.717238</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>216</td>\n",
       "      <td>336.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>8.586157</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     H    W    C_x    C_y  gps_dist vehicle  vehicle_dummy\n",
       "0  185  286  303.0  444.5  7.507966     car              1\n",
       "1  185  286  303.0  441.5  7.507966     car              1\n",
       "2  182  280  302.0  440.0  7.507966     car              1\n",
       "3  174  266  309.0  439.0  7.717238     car              1\n",
       "4  142  216  336.0  423.0  8.586157     car              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping camera height \n",
    "df['vehicle_dummy']= pd.get_dummies(df.vehicle).car\n",
    "#mapping = {10:45, 12:60, 13:28, 17:79.5}\n",
    "#df.replace({\"unit\": mapping}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df[['H', 'W', 'C_x', 'C_y',  'vehicle','vehicle_dummy']].values\n",
    "y = df[['gps_dist']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82, 104, 642.0, 432.0, 'truck', 0],\n",
       "       [66, 100, 398.0, 403.0, 'car', 1],\n",
       "       [45, 48, 442.0, 389.5, 'truck', 0],\n",
       "       ...,\n",
       "       [47, 48, 506.0, 428.5, 'car', 1],\n",
       "       [37, 52, 484.0, 457.5, 'car', 1],\n",
       "       [47, 52, 496.0, 430.5, 'truck', 0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_train = pd.DataFrame(X_train, columns=['H', 'W', 'C_x', 'C_y',  'vehicle','vehicle_dummy'])\n",
    "df_reg_train['gps_dist'] = y_train\n",
    "df_reg_test = pd.DataFrame(X_test, columns=['H', 'W', 'C_x', 'C_y',  'vehicle','vehicle_dummy'])\n",
    "df_reg_test['gps_dist'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dictionary to convert specific columns\n",
    "convert_dict = {'H': float,\n",
    "                'W': float,\n",
    "                'C_x': float,\n",
    "                'C_y': float,\n",
    "                'vehicle_dummy': float,\n",
    "                'gps_dist': float,\n",
    "                'vehicle': str\n",
    "               }\n",
    "df_reg_train = df_reg_train.astype(convert_dict)\n",
    "df_reg_test = df_reg_test.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>C_x</th>\n",
       "      <th>C_y</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "      <th>gps_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.110817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.022805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>389.5</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.909683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.514592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>439.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.943693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>103.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>500.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.147214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>145.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>442.5</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.056597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>428.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.338742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>457.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.970192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>47.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>430.5</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.228752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1900 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          H      W    C_x    C_y vehicle  vehicle_dummy   gps_dist\n",
       "0      82.0  104.0  642.0  432.0   truck            0.0  23.110817\n",
       "1      66.0  100.0  398.0  403.0     car            1.0  16.022805\n",
       "2      45.0   48.0  442.0  389.5   truck            0.0  36.909683\n",
       "3     116.0  120.0  468.0  447.0   truck            0.0  16.514592\n",
       "4      23.0   38.0  491.0  439.5     car            1.0  42.943693\n",
       "...     ...    ...    ...    ...     ...            ...        ...\n",
       "1895  103.0  128.0  448.0  500.5     car            1.0  12.147214\n",
       "1896  145.0  206.0  743.0  442.5   truck            0.0  15.056597\n",
       "1897   47.0   48.0  506.0  428.5     car            1.0  37.338742\n",
       "1898   37.0   52.0  484.0  457.5     car            1.0  31.970192\n",
       "1899   47.0   52.0  496.0  430.5   truck            0.0  35.228752\n",
       "\n",
       "[1900 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>C_x</th>\n",
       "      <th>C_y</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "      <th>gps_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>420.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.382472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.947480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.683308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>382.5</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.909683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.373707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>426.5</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.604501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>428.5</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.947317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.540706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.512966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.601233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         H      W    C_x    C_y vehicle  vehicle_dummy   gps_dist\n",
       "0    121.0  166.0  385.0  420.5     car            1.0  15.382472\n",
       "1    180.0  204.0  390.0  471.0     car            1.0  15.947480\n",
       "2     60.0   78.0  483.0  442.0     car            1.0  22.683308\n",
       "3     45.0   50.0  429.0  382.5   truck            0.0  36.909683\n",
       "4     26.0   40.0  516.0  425.0     car            1.0  43.373707\n",
       "..     ...    ...    ...    ...     ...            ...        ...\n",
       "470   39.0   44.0  504.0  426.5     car            1.0  42.604501\n",
       "471   47.0   50.0  507.0  428.5   truck            0.0  35.947317\n",
       "472   52.0   56.0  430.0  386.0   truck            0.0  33.540706\n",
       "473   50.0   56.0  518.0  430.0   truck            0.0  33.512966\n",
       "474   52.0   60.0  540.0  431.0   truck            0.0  34.601233\n",
       "\n",
       "[475 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model_dic = {}\n",
    "df_reg_final = pd.DataFrame()\n",
    "for name, group in df_reg_train.groupby('unit'):\n",
    "    df_reg_train_tmp = df_reg_train[df_reg_train.unit == name]\n",
    "    df_reg_test_tmp = df_reg_test[df_reg_test.unit == name]\n",
    "    mod = smf.ols(formula=\"gps_dist ~ C(vehicle) + H + W + C_x + C_y\", data=df_reg_train_tmp)\n",
    "    res = mod.fit()\n",
    "    df_reg_test_tmp_p = df_reg_test_tmp[['vehicle', 'H', 'W', 'C_x', 'C_y']]\n",
    "    df_reg_test_tmp['predict'] = res.predict(df_reg_test_tmp_p)\n",
    "    df_reg_final = pd.concat([df_reg_final, df_reg_test_tmp])\n",
    "    model_dic[str(name)] = [res, df_reg_test_tmp['predict'] - df_reg_test_tmp['gps_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "\n",
      "unit:  28.0\n",
      "mean:  -0.0014094277608245206 std:  5.507081871717395\n",
      "\n",
      "unit:  45.0\n",
      "mean:  0.9876773340943985 std:  7.106748015924014\n",
      "\n",
      "unit:  60.0\n",
      "mean:  -0.6251965311032601 std:  8.905476906553893\n",
      "\n",
      "unit:  79.5\n",
      "mean:  -1.297796057054885 std:  8.91754237978122\n",
      "\n",
      "truck\n",
      "\n",
      "unit:  28.0\n",
      "mean:  -0.0014094277608245206 std:  5.507081871717395\n",
      "\n",
      "unit:  45.0\n",
      "mean:  0.9876773340943985 std:  7.106748015924014\n",
      "\n",
      "unit:  60.0\n",
      "mean:  -0.6251965311032601 std:  8.905476906553893\n",
      "\n",
      "unit:  79.5\n",
      "mean:  -1.297796057054885 std:  8.91754237978122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "for n , g in df_reg_final.groupby('vehicle'): \n",
    "    print(n)\n",
    "    print('')\n",
    "    for name, group in df_reg_final.groupby('unit'):\n",
    "        res =  group.predict - group.gps_dist\n",
    "        print('unit: ', name)\n",
    "        print('mean: ', np.mean(res),'std: ', np.std(res))\n",
    "        print('')\n",
    "        r.append([np.mean(res), np.std(res), name, 'reg', n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(r,columns=['mean','std','unit','model','vehicle'])\n",
    "df_result = pd.concat([df_result,r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_train_ann = np.delete(X_train, -2, 1)\n",
    "X_test_ann = np.delete(X_test, -2, 1)\n",
    "sc = StandardScaler()\n",
    "X_train_ann = sc.fit_transform(X_train_ann)\n",
    "X_test_ann = sc.transform(X_test_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "95/95 [==============================] - 1s 3ms/step - loss: 1024.1274 - soft_acc: 0.0000e+00 - val_loss: 1078.5704 - val_soft_acc: 0.0000e+00\n",
      "Epoch 2/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 999.7444 - soft_acc: 0.0000e+00 - val_loss: 1017.1218 - val_soft_acc: 0.0000e+00\n",
      "Epoch 3/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 755.8896 - soft_acc: 0.0033 - val_loss: 476.7351 - val_soft_acc: 0.0130\n",
      "Epoch 4/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 183.8949 - soft_acc: 0.0309 - val_loss: 76.5377 - val_soft_acc: 0.0295\n",
      "Epoch 5/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 55.7475 - soft_acc: 0.0421 - val_loss: 42.2718 - val_soft_acc: 0.0521\n",
      "Epoch 6/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 36.4313 - soft_acc: 0.0855 - val_loss: 32.2839 - val_soft_acc: 0.1233\n",
      "Epoch 7/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 29.8572 - soft_acc: 0.1178 - val_loss: 29.2748 - val_soft_acc: 0.1033\n",
      "Epoch 8/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 28.0149 - soft_acc: 0.1039 - val_loss: 28.8123 - val_soft_acc: 0.1319\n",
      "Epoch 9/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 26.5082 - soft_acc: 0.1171 - val_loss: 27.9373 - val_soft_acc: 0.1198\n",
      "Epoch 10/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 25.5500 - soft_acc: 0.1237 - val_loss: 27.5516 - val_soft_acc: 0.1562\n",
      "Epoch 11/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 24.6347 - soft_acc: 0.1283 - val_loss: 27.1538 - val_soft_acc: 0.1562\n",
      "Epoch 12/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 23.6422 - soft_acc: 0.1349 - val_loss: 28.0426 - val_soft_acc: 0.1658\n",
      "Epoch 13/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 23.1635 - soft_acc: 0.1355 - val_loss: 27.1012 - val_soft_acc: 0.1658\n",
      "Epoch 14/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 22.2915 - soft_acc: 0.1289 - val_loss: 25.8854 - val_soft_acc: 0.1571\n",
      "Epoch 15/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 21.4954 - soft_acc: 0.1355 - val_loss: 25.3144 - val_soft_acc: 0.1736\n",
      "Epoch 16/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 20.9278 - soft_acc: 0.1507 - val_loss: 25.1400 - val_soft_acc: 0.1918\n",
      "Epoch 17/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 20.3420 - soft_acc: 0.1434 - val_loss: 24.9407 - val_soft_acc: 0.1753\n",
      "Epoch 18/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 19.9543 - soft_acc: 0.1579 - val_loss: 24.9056 - val_soft_acc: 0.1701\n",
      "Epoch 19/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 19.2220 - soft_acc: 0.1520 - val_loss: 23.2635 - val_soft_acc: 0.1667\n",
      "Epoch 20/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 18.8157 - soft_acc: 0.1500 - val_loss: 22.5646 - val_soft_acc: 0.1606\n",
      "Epoch 21/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 18.3378 - soft_acc: 0.1441 - val_loss: 22.3437 - val_soft_acc: 0.1667\n",
      "Epoch 22/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 17.8085 - soft_acc: 0.1579 - val_loss: 21.7186 - val_soft_acc: 0.1675\n",
      "Epoch 23/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 17.3205 - soft_acc: 0.1487 - val_loss: 20.8266 - val_soft_acc: 0.1484\n",
      "Epoch 24/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 16.7139 - soft_acc: 0.1382 - val_loss: 21.7993 - val_soft_acc: 0.2031\n",
      "Epoch 25/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 16.1530 - soft_acc: 0.1553 - val_loss: 20.0033 - val_soft_acc: 0.1554\n",
      "Epoch 26/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 15.7532 - soft_acc: 0.1592 - val_loss: 19.3657 - val_soft_acc: 0.1424\n",
      "Epoch 27/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 15.2495 - soft_acc: 0.1533 - val_loss: 19.6747 - val_soft_acc: 0.1884\n",
      "Epoch 28/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 14.9194 - soft_acc: 0.1618 - val_loss: 18.3860 - val_soft_acc: 0.1597\n",
      "Epoch 29/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 14.4866 - soft_acc: 0.1757 - val_loss: 18.2225 - val_soft_acc: 0.1753\n",
      "Epoch 30/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 14.0600 - soft_acc: 0.1599 - val_loss: 17.5391 - val_soft_acc: 0.1424\n",
      "Epoch 31/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 13.7709 - soft_acc: 0.1711 - val_loss: 17.7169 - val_soft_acc: 0.1762\n",
      "Epoch 32/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 13.3923 - soft_acc: 0.1678 - val_loss: 17.0164 - val_soft_acc: 0.1684\n",
      "Epoch 33/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 13.1049 - soft_acc: 0.1809 - val_loss: 16.9591 - val_soft_acc: 0.1632\n",
      "Epoch 34/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.9970 - soft_acc: 0.1776 - val_loss: 16.5371 - val_soft_acc: 0.1823\n",
      "Epoch 35/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.7481 - soft_acc: 0.1704 - val_loss: 16.8082 - val_soft_acc: 0.1684\n",
      "Epoch 36/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.4923 - soft_acc: 0.1704 - val_loss: 16.8909 - val_soft_acc: 0.1858\n",
      "Epoch 37/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.3808 - soft_acc: 0.1803 - val_loss: 16.3058 - val_soft_acc: 0.1771\n",
      "Epoch 38/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.1608 - soft_acc: 0.1638 - val_loss: 15.7072 - val_soft_acc: 0.1502\n",
      "Epoch 39/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 12.2041 - soft_acc: 0.1632 - val_loss: 15.1353 - val_soft_acc: 0.1667\n",
      "Epoch 40/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.8988 - soft_acc: 0.1796 - val_loss: 15.3466 - val_soft_acc: 0.1710\n",
      "Epoch 41/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.9543 - soft_acc: 0.1592 - val_loss: 15.2705 - val_soft_acc: 0.1806\n",
      "Epoch 42/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.7380 - soft_acc: 0.1651 - val_loss: 15.1464 - val_soft_acc: 0.1788\n",
      "Epoch 43/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.5867 - soft_acc: 0.1684 - val_loss: 14.5389 - val_soft_acc: 0.1510\n",
      "Epoch 44/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.4856 - soft_acc: 0.1737 - val_loss: 14.5108 - val_soft_acc: 0.1780\n",
      "Epoch 45/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.4543 - soft_acc: 0.1678 - val_loss: 15.0827 - val_soft_acc: 0.1780\n",
      "Epoch 46/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.3903 - soft_acc: 0.1691 - val_loss: 14.3489 - val_soft_acc: 0.1780\n",
      "Epoch 47/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.2012 - soft_acc: 0.1776 - val_loss: 14.4972 - val_soft_acc: 0.1623\n",
      "Epoch 48/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.3863 - soft_acc: 0.1691 - val_loss: 14.1267 - val_soft_acc: 0.1727\n",
      "Epoch 49/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 11.2146 - soft_acc: 0.1592 - val_loss: 14.5388 - val_soft_acc: 0.1667\n",
      "Epoch 50/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.1868 - soft_acc: 0.1711 - val_loss: 14.3115 - val_soft_acc: 0.1736\n",
      "Epoch 51/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.0698 - soft_acc: 0.1632 - val_loss: 13.5347 - val_soft_acc: 0.1675\n",
      "Epoch 52/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.2155 - soft_acc: 0.1678 - val_loss: 14.0301 - val_soft_acc: 0.1658\n",
      "Epoch 53/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.0326 - soft_acc: 0.1658 - val_loss: 13.7445 - val_soft_acc: 0.1641\n",
      "Epoch 54/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.9574 - soft_acc: 0.1586 - val_loss: 14.2967 - val_soft_acc: 0.1580\n",
      "Epoch 55/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 11.0411 - soft_acc: 0.1638 - val_loss: 13.3663 - val_soft_acc: 0.1806\n",
      "Epoch 56/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.9469 - soft_acc: 0.1750 - val_loss: 13.7721 - val_soft_acc: 0.1589\n",
      "Epoch 57/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.9174 - soft_acc: 0.1645 - val_loss: 14.0395 - val_soft_acc: 0.1866\n",
      "Epoch 58/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.9857 - soft_acc: 0.1579 - val_loss: 13.5274 - val_soft_acc: 0.1684\n",
      "Epoch 59/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.7869 - soft_acc: 0.1546 - val_loss: 13.3894 - val_soft_acc: 0.1753\n",
      "Epoch 60/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 10.7544 - soft_acc: 0.1658 - val_loss: 13.2756 - val_soft_acc: 0.1745\n",
      "Epoch 61/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.6883 - soft_acc: 0.1717 - val_loss: 13.3545 - val_soft_acc: 0.1562\n",
      "Epoch 62/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.6181 - soft_acc: 0.1770 - val_loss: 14.6858 - val_soft_acc: 0.1745\n",
      "Epoch 63/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.7654 - soft_acc: 0.1809 - val_loss: 13.4542 - val_soft_acc: 0.1780\n",
      "Epoch 64/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.6448 - soft_acc: 0.1625 - val_loss: 13.3116 - val_soft_acc: 0.1806\n",
      "Epoch 65/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.5913 - soft_acc: 0.1789 - val_loss: 14.7393 - val_soft_acc: 0.1372\n",
      "Epoch 66/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.5321 - soft_acc: 0.1737 - val_loss: 13.2451 - val_soft_acc: 0.1727\n",
      "Epoch 67/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.5652 - soft_acc: 0.1711 - val_loss: 13.2062 - val_soft_acc: 0.1684\n",
      "Epoch 68/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.3749 - soft_acc: 0.1816 - val_loss: 13.1069 - val_soft_acc: 0.1901\n",
      "Epoch 69/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.3775 - soft_acc: 0.1803 - val_loss: 13.1598 - val_soft_acc: 0.2040\n",
      "Epoch 70/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.4427 - soft_acc: 0.1724 - val_loss: 13.3604 - val_soft_acc: 0.1866\n",
      "Epoch 71/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.4023 - soft_acc: 0.1776 - val_loss: 13.3584 - val_soft_acc: 0.1970\n",
      "Epoch 72/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.3487 - soft_acc: 0.1796 - val_loss: 13.1816 - val_soft_acc: 0.1970\n",
      "Epoch 73/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.4614 - soft_acc: 0.1803 - val_loss: 13.4911 - val_soft_acc: 0.1866\n",
      "Epoch 74/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.3327 - soft_acc: 0.1684 - val_loss: 13.5112 - val_soft_acc: 0.1441\n",
      "Epoch 75/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.1722 - soft_acc: 0.1717 - val_loss: 13.2323 - val_soft_acc: 0.1832\n",
      "Epoch 76/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.4100 - soft_acc: 0.1763 - val_loss: 13.2100 - val_soft_acc: 0.1832\n",
      "Epoch 77/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.2276 - soft_acc: 0.1770 - val_loss: 13.5728 - val_soft_acc: 0.1658\n",
      "Epoch 78/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.3066 - soft_acc: 0.1783 - val_loss: 13.9574 - val_soft_acc: 0.2127\n",
      "Epoch 79/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.0369 - soft_acc: 0.1849 - val_loss: 13.1435 - val_soft_acc: 0.2031\n",
      "Epoch 80/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.2352 - soft_acc: 0.1770 - val_loss: 13.5047 - val_soft_acc: 0.1875\n",
      "Epoch 81/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.1611 - soft_acc: 0.1717 - val_loss: 13.6141 - val_soft_acc: 0.1988\n",
      "Epoch 82/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.0620 - soft_acc: 0.1816 - val_loss: 13.5110 - val_soft_acc: 0.1710\n",
      "Epoch 83/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.9929 - soft_acc: 0.1855 - val_loss: 13.2135 - val_soft_acc: 0.1910\n",
      "Epoch 84/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.1181 - soft_acc: 0.1776 - val_loss: 13.3970 - val_soft_acc: 0.1285\n",
      "Epoch 85/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.0921 - soft_acc: 0.1796 - val_loss: 13.0982 - val_soft_acc: 0.1944\n",
      "Epoch 86/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 10.1169 - soft_acc: 0.1783 - val_loss: 12.7770 - val_soft_acc: 0.1866\n",
      "Epoch 87/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.9605 - soft_acc: 0.1671 - val_loss: 12.6773 - val_soft_acc: 0.1997\n",
      "Epoch 88/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7942 - soft_acc: 0.1967 - val_loss: 13.1356 - val_soft_acc: 0.1632\n",
      "Epoch 89/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.8105 - soft_acc: 0.1842 - val_loss: 13.8287 - val_soft_acc: 0.1727\n",
      "Epoch 90/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.8235 - soft_acc: 0.1954 - val_loss: 12.9261 - val_soft_acc: 0.1884\n",
      "Epoch 91/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.8122 - soft_acc: 0.1882 - val_loss: 12.7993 - val_soft_acc: 0.2014\n",
      "Epoch 92/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.8520 - soft_acc: 0.1836 - val_loss: 13.0037 - val_soft_acc: 0.1840\n",
      "Epoch 93/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7796 - soft_acc: 0.1888 - val_loss: 12.9167 - val_soft_acc: 0.1753\n",
      "Epoch 94/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.8930 - soft_acc: 0.1875 - val_loss: 12.7003 - val_soft_acc: 0.1849\n",
      "Epoch 95/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7241 - soft_acc: 0.1836 - val_loss: 12.7614 - val_soft_acc: 0.1866\n",
      "Epoch 96/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7430 - soft_acc: 0.1836 - val_loss: 12.6161 - val_soft_acc: 0.1554\n",
      "Epoch 97/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7421 - soft_acc: 0.1724 - val_loss: 13.1597 - val_soft_acc: 0.1606\n",
      "Epoch 98/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6827 - soft_acc: 0.1842 - val_loss: 12.6620 - val_soft_acc: 0.1753\n",
      "Epoch 99/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6552 - soft_acc: 0.1822 - val_loss: 12.8312 - val_soft_acc: 0.1823\n",
      "Epoch 100/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6688 - soft_acc: 0.1757 - val_loss: 12.5317 - val_soft_acc: 0.1745\n",
      "Epoch 101/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7383 - soft_acc: 0.1678 - val_loss: 12.5727 - val_soft_acc: 0.1710\n",
      "Epoch 102/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6484 - soft_acc: 0.1684 - val_loss: 12.5962 - val_soft_acc: 0.1962\n",
      "Epoch 103/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7058 - soft_acc: 0.1783 - val_loss: 12.8746 - val_soft_acc: 0.1398\n",
      "Epoch 104/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5837 - soft_acc: 0.1855 - val_loss: 13.8439 - val_soft_acc: 0.1719\n",
      "Epoch 105/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7837 - soft_acc: 0.1717 - val_loss: 12.4173 - val_soft_acc: 0.1858\n",
      "Epoch 106/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5847 - soft_acc: 0.1836 - val_loss: 12.7544 - val_soft_acc: 0.1970\n",
      "Epoch 107/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5706 - soft_acc: 0.1717 - val_loss: 13.4309 - val_soft_acc: 0.1823\n",
      "Epoch 108/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6804 - soft_acc: 0.1836 - val_loss: 12.5366 - val_soft_acc: 0.1823\n",
      "Epoch 109/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5510 - soft_acc: 0.1684 - val_loss: 12.5563 - val_soft_acc: 0.1719\n",
      "Epoch 110/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5429 - soft_acc: 0.1776 - val_loss: 12.6396 - val_soft_acc: 0.1806\n",
      "Epoch 111/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4640 - soft_acc: 0.1796 - val_loss: 14.2989 - val_soft_acc: 0.1936\n",
      "Epoch 112/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.6585 - soft_acc: 0.1796 - val_loss: 12.6630 - val_soft_acc: 0.1693\n",
      "Epoch 113/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5354 - soft_acc: 0.1822 - val_loss: 12.6300 - val_soft_acc: 0.2109\n",
      "Epoch 114/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5145 - soft_acc: 0.1776 - val_loss: 12.7328 - val_soft_acc: 0.2135\n",
      "Epoch 115/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5954 - soft_acc: 0.1724 - val_loss: 12.3358 - val_soft_acc: 0.1988\n",
      "Epoch 116/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.7109 - soft_acc: 0.1750 - val_loss: 12.2824 - val_soft_acc: 0.1406\n",
      "Epoch 117/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5433 - soft_acc: 0.1888 - val_loss: 13.4545 - val_soft_acc: 0.1840\n",
      "Epoch 118/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5205 - soft_acc: 0.1776 - val_loss: 12.3565 - val_soft_acc: 0.1545\n",
      "Epoch 119/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5539 - soft_acc: 0.1921 - val_loss: 12.2595 - val_soft_acc: 0.1580\n",
      "Epoch 120/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4038 - soft_acc: 0.1789 - val_loss: 12.3635 - val_soft_acc: 0.1806\n",
      "Epoch 121/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5321 - soft_acc: 0.1862 - val_loss: 12.6455 - val_soft_acc: 0.1936\n",
      "Epoch 122/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5893 - soft_acc: 0.1737 - val_loss: 12.7803 - val_soft_acc: 0.2292\n",
      "Epoch 123/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5783 - soft_acc: 0.1763 - val_loss: 12.1401 - val_soft_acc: 0.1901\n",
      "Epoch 124/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3348 - soft_acc: 0.1921 - val_loss: 12.4737 - val_soft_acc: 0.1997\n",
      "Epoch 125/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5418 - soft_acc: 0.1737 - val_loss: 12.7060 - val_soft_acc: 0.1823\n",
      "Epoch 126/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3991 - soft_acc: 0.1842 - val_loss: 13.1115 - val_soft_acc: 0.1944\n",
      "Epoch 127/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4650 - soft_acc: 0.1783 - val_loss: 12.6095 - val_soft_acc: 0.1979\n",
      "Epoch 128/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4919 - soft_acc: 0.1849 - val_loss: 12.3390 - val_soft_acc: 0.1571\n",
      "Epoch 129/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5863 - soft_acc: 0.1803 - val_loss: 12.8361 - val_soft_acc: 0.2066\n",
      "Epoch 130/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5046 - soft_acc: 0.1882 - val_loss: 12.3290 - val_soft_acc: 0.1892\n",
      "Epoch 131/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4034 - soft_acc: 0.1829 - val_loss: 12.0880 - val_soft_acc: 0.1398\n",
      "Epoch 132/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4406 - soft_acc: 0.1908 - val_loss: 12.0317 - val_soft_acc: 0.1962\n",
      "Epoch 133/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3368 - soft_acc: 0.1961 - val_loss: 12.2081 - val_soft_acc: 0.1944\n",
      "Epoch 134/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3157 - soft_acc: 0.1743 - val_loss: 12.5030 - val_soft_acc: 0.2109\n",
      "Epoch 135/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3748 - soft_acc: 0.1822 - val_loss: 12.4368 - val_soft_acc: 0.1380\n",
      "Epoch 136/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4803 - soft_acc: 0.1684 - val_loss: 12.3870 - val_soft_acc: 0.2101\n",
      "Epoch 137/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4806 - soft_acc: 0.1836 - val_loss: 12.7943 - val_soft_acc: 0.2075\n",
      "Epoch 138/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4785 - soft_acc: 0.1836 - val_loss: 12.8636 - val_soft_acc: 0.2005\n",
      "Epoch 139/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3479 - soft_acc: 0.1888 - val_loss: 12.4555 - val_soft_acc: 0.1806\n",
      "Epoch 140/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4034 - soft_acc: 0.1895 - val_loss: 12.3570 - val_soft_acc: 0.1675\n",
      "Epoch 141/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.5001 - soft_acc: 0.1836 - val_loss: 12.5813 - val_soft_acc: 0.2057\n",
      "Epoch 142/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4131 - soft_acc: 0.1855 - val_loss: 12.5513 - val_soft_acc: 0.2161\n",
      "Epoch 143/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4627 - soft_acc: 0.1803 - val_loss: 13.5469 - val_soft_acc: 0.2066\n",
      "Epoch 144/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4252 - soft_acc: 0.1822 - val_loss: 13.0415 - val_soft_acc: 0.2144\n",
      "Epoch 145/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4563 - soft_acc: 0.1763 - val_loss: 13.5034 - val_soft_acc: 0.2040\n",
      "Epoch 146/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3970 - soft_acc: 0.1921 - val_loss: 12.2536 - val_soft_acc: 0.1927\n",
      "Epoch 147/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3163 - soft_acc: 0.1822 - val_loss: 12.1589 - val_soft_acc: 0.1554\n",
      "Epoch 148/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4495 - soft_acc: 0.1954 - val_loss: 12.5244 - val_soft_acc: 0.2266\n",
      "Epoch 149/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3032 - soft_acc: 0.1789 - val_loss: 12.4722 - val_soft_acc: 0.1771\n",
      "Epoch 150/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3286 - soft_acc: 0.1882 - val_loss: 13.1183 - val_soft_acc: 0.1615\n",
      "Epoch 151/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4850 - soft_acc: 0.1750 - val_loss: 13.2895 - val_soft_acc: 0.1962\n",
      "Epoch 152/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4195 - soft_acc: 0.1816 - val_loss: 12.3107 - val_soft_acc: 0.1823\n",
      "Epoch 153/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2768 - soft_acc: 0.1796 - val_loss: 13.2650 - val_soft_acc: 0.2083\n",
      "Epoch 154/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3345 - soft_acc: 0.1855 - val_loss: 13.0933 - val_soft_acc: 0.1936\n",
      "Epoch 155/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2854 - soft_acc: 0.1776 - val_loss: 12.4035 - val_soft_acc: 0.1797\n",
      "Epoch 156/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3571 - soft_acc: 0.1862 - val_loss: 12.3990 - val_soft_acc: 0.1649\n",
      "Epoch 157/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4888 - soft_acc: 0.1855 - val_loss: 12.3029 - val_soft_acc: 0.1979\n",
      "Epoch 158/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.4683 - soft_acc: 0.1770 - val_loss: 12.2477 - val_soft_acc: 0.1936\n",
      "Epoch 159/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3453 - soft_acc: 0.1974 - val_loss: 12.8619 - val_soft_acc: 0.2283\n",
      "Epoch 160/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2876 - soft_acc: 0.1882 - val_loss: 12.1719 - val_soft_acc: 0.2153\n",
      "Epoch 161/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2615 - soft_acc: 0.1803 - val_loss: 12.3914 - val_soft_acc: 0.2040\n",
      "Epoch 162/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3540 - soft_acc: 0.1743 - val_loss: 13.6129 - val_soft_acc: 0.2101\n",
      "Epoch 163/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3487 - soft_acc: 0.1868 - val_loss: 12.8572 - val_soft_acc: 0.1979\n",
      "Epoch 164/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2663 - soft_acc: 0.1934 - val_loss: 12.1431 - val_soft_acc: 0.1997\n",
      "Epoch 165/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2337 - soft_acc: 0.1921 - val_loss: 12.4481 - val_soft_acc: 0.1858\n",
      "Epoch 166/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3428 - soft_acc: 0.1882 - val_loss: 12.0968 - val_soft_acc: 0.1823\n",
      "Epoch 167/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2122 - soft_acc: 0.1757 - val_loss: 13.3607 - val_soft_acc: 0.1988\n",
      "Epoch 168/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3063 - soft_acc: 0.1928 - val_loss: 12.4672 - val_soft_acc: 0.2118\n",
      "Epoch 169/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2913 - soft_acc: 0.1730 - val_loss: 12.7679 - val_soft_acc: 0.2205\n",
      "Epoch 170/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2616 - soft_acc: 0.1901 - val_loss: 12.1240 - val_soft_acc: 0.1649\n",
      "Epoch 171/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3914 - soft_acc: 0.1987 - val_loss: 12.4125 - val_soft_acc: 0.1944\n",
      "Epoch 172/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3716 - soft_acc: 0.1717 - val_loss: 12.7910 - val_soft_acc: 0.1684\n",
      "Epoch 173/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3007 - soft_acc: 0.1914 - val_loss: 12.3796 - val_soft_acc: 0.1988\n",
      "Epoch 174/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2228 - soft_acc: 0.1901 - val_loss: 13.5592 - val_soft_acc: 0.2127\n",
      "Epoch 175/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3796 - soft_acc: 0.1849 - val_loss: 11.9477 - val_soft_acc: 0.1849\n",
      "Epoch 176/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2788 - soft_acc: 0.1855 - val_loss: 13.4790 - val_soft_acc: 0.2075\n",
      "Epoch 177/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2893 - soft_acc: 0.1776 - val_loss: 12.4686 - val_soft_acc: 0.1866\n",
      "Epoch 178/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2556 - soft_acc: 0.1914 - val_loss: 12.3060 - val_soft_acc: 0.2283\n",
      "Epoch 179/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2888 - soft_acc: 0.1914 - val_loss: 12.3657 - val_soft_acc: 0.1675\n",
      "Epoch 180/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2545 - soft_acc: 0.1789 - val_loss: 12.1599 - val_soft_acc: 0.1701\n",
      "Epoch 181/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1851 - soft_acc: 0.1855 - val_loss: 12.7966 - val_soft_acc: 0.2196\n",
      "Epoch 182/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2490 - soft_acc: 0.1855 - val_loss: 12.2671 - val_soft_acc: 0.1510\n",
      "Epoch 183/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1473 - soft_acc: 0.1908 - val_loss: 12.2710 - val_soft_acc: 0.1936\n",
      "Epoch 184/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1968 - soft_acc: 0.1875 - val_loss: 12.3097 - val_soft_acc: 0.1970\n",
      "Epoch 185/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1909 - soft_acc: 0.1921 - val_loss: 12.6609 - val_soft_acc: 0.1997\n",
      "Epoch 186/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3418 - soft_acc: 0.1789 - val_loss: 12.2472 - val_soft_acc: 0.1536\n",
      "Epoch 187/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2052 - soft_acc: 0.1822 - val_loss: 12.4057 - val_soft_acc: 0.1632\n",
      "Epoch 188/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2780 - soft_acc: 0.2000 - val_loss: 13.1787 - val_soft_acc: 0.1823\n",
      "Epoch 189/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3140 - soft_acc: 0.1763 - val_loss: 12.3634 - val_soft_acc: 0.2153\n",
      "Epoch 190/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2339 - soft_acc: 0.1882 - val_loss: 13.0312 - val_soft_acc: 0.1979\n",
      "Epoch 191/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3336 - soft_acc: 0.1770 - val_loss: 12.3386 - val_soft_acc: 0.1693\n",
      "Epoch 192/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2546 - soft_acc: 0.1803 - val_loss: 12.0998 - val_soft_acc: 0.2040\n",
      "Epoch 193/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1468 - soft_acc: 0.1783 - val_loss: 12.6060 - val_soft_acc: 0.2274\n",
      "Epoch 194/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1908 - soft_acc: 0.1987 - val_loss: 12.2843 - val_soft_acc: 0.1562\n",
      "Epoch 195/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3080 - soft_acc: 0.1849 - val_loss: 12.4326 - val_soft_acc: 0.2057\n",
      "Epoch 196/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2150 - soft_acc: 0.1862 - val_loss: 12.3006 - val_soft_acc: 0.1806\n",
      "Epoch 197/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1819 - soft_acc: 0.1836 - val_loss: 12.3068 - val_soft_acc: 0.1970\n",
      "Epoch 198/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1614 - soft_acc: 0.1829 - val_loss: 12.3948 - val_soft_acc: 0.2066\n",
      "Epoch 199/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1900 - soft_acc: 0.1855 - val_loss: 12.6211 - val_soft_acc: 0.2170\n",
      "Epoch 200/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1321 - soft_acc: 0.1875 - val_loss: 12.4353 - val_soft_acc: 0.1675\n",
      "Epoch 201/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1845 - soft_acc: 0.2026 - val_loss: 12.2399 - val_soft_acc: 0.1658\n",
      "Epoch 202/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2056 - soft_acc: 0.1908 - val_loss: 12.4703 - val_soft_acc: 0.1606\n",
      "Epoch 203/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2473 - soft_acc: 0.1868 - val_loss: 12.2742 - val_soft_acc: 0.1962\n",
      "Epoch 204/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.2324 - soft_acc: 0.1947 - val_loss: 12.8896 - val_soft_acc: 0.2188\n",
      "Epoch 205/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.2851 - soft_acc: 0.1789 - val_loss: 12.4094 - val_soft_acc: 0.1580\n",
      "Epoch 206/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.2373 - soft_acc: 0.1914 - val_loss: 12.6137 - val_soft_acc: 0.1736\n",
      "Epoch 207/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1146 - soft_acc: 0.1829 - val_loss: 13.6396 - val_soft_acc: 0.1615\n",
      "Epoch 208/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1835 - soft_acc: 0.1809 - val_loss: 12.1322 - val_soft_acc: 0.1849\n",
      "Epoch 209/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0886 - soft_acc: 0.1750 - val_loss: 12.0774 - val_soft_acc: 0.2092\n",
      "Epoch 210/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2805 - soft_acc: 0.1987 - val_loss: 13.0172 - val_soft_acc: 0.2292\n",
      "Epoch 211/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2711 - soft_acc: 0.1901 - val_loss: 12.3198 - val_soft_acc: 0.2014\n",
      "Epoch 212/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3182 - soft_acc: 0.1888 - val_loss: 12.1347 - val_soft_acc: 0.1658\n",
      "Epoch 213/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1384 - soft_acc: 0.1868 - val_loss: 12.8721 - val_soft_acc: 0.1858\n",
      "Epoch 214/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1621 - soft_acc: 0.1993 - val_loss: 12.2741 - val_soft_acc: 0.1536\n",
      "Epoch 215/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1061 - soft_acc: 0.1822 - val_loss: 12.7998 - val_soft_acc: 0.2231\n",
      "Epoch 216/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2330 - soft_acc: 0.1908 - val_loss: 12.3843 - val_soft_acc: 0.2014\n",
      "Epoch 217/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2402 - soft_acc: 0.1816 - val_loss: 12.3275 - val_soft_acc: 0.1727\n",
      "Epoch 218/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1946 - soft_acc: 0.1836 - val_loss: 12.5679 - val_soft_acc: 0.1380\n",
      "Epoch 219/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1871 - soft_acc: 0.1928 - val_loss: 12.6360 - val_soft_acc: 0.2222\n",
      "Epoch 220/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0724 - soft_acc: 0.1895 - val_loss: 12.6840 - val_soft_acc: 0.2092\n",
      "Epoch 221/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1538 - soft_acc: 0.2007 - val_loss: 12.4486 - val_soft_acc: 0.1832\n",
      "Epoch 222/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1923 - soft_acc: 0.2007 - val_loss: 12.4584 - val_soft_acc: 0.2101\n",
      "Epoch 223/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2394 - soft_acc: 0.1928 - val_loss: 12.1960 - val_soft_acc: 0.2170\n",
      "Epoch 224/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0612 - soft_acc: 0.1914 - val_loss: 12.2456 - val_soft_acc: 0.2309\n",
      "Epoch 225/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1041 - soft_acc: 0.1987 - val_loss: 12.4159 - val_soft_acc: 0.1979\n",
      "Epoch 226/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0809 - soft_acc: 0.1757 - val_loss: 12.2369 - val_soft_acc: 0.1615\n",
      "Epoch 227/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1904 - soft_acc: 0.1862 - val_loss: 12.6163 - val_soft_acc: 0.2257\n",
      "Epoch 228/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1267 - soft_acc: 0.1921 - val_loss: 12.0983 - val_soft_acc: 0.1719\n",
      "Epoch 229/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1014 - soft_acc: 0.1730 - val_loss: 12.4588 - val_soft_acc: 0.1910\n",
      "Epoch 230/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1099 - soft_acc: 0.1862 - val_loss: 12.4923 - val_soft_acc: 0.2378\n",
      "Epoch 231/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1406 - soft_acc: 0.1875 - val_loss: 12.8904 - val_soft_acc: 0.2092\n",
      "Epoch 232/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2131 - soft_acc: 0.1836 - val_loss: 12.4407 - val_soft_acc: 0.2179\n",
      "Epoch 233/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2052 - soft_acc: 0.1868 - val_loss: 12.1994 - val_soft_acc: 0.2231\n",
      "Epoch 234/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1615 - soft_acc: 0.1855 - val_loss: 12.6272 - val_soft_acc: 0.2188\n",
      "Epoch 235/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0998 - soft_acc: 0.1921 - val_loss: 12.1146 - val_soft_acc: 0.2057\n",
      "Epoch 236/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9975 - soft_acc: 0.1875 - val_loss: 13.0564 - val_soft_acc: 0.2188\n",
      "Epoch 237/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3886 - soft_acc: 0.1961 - val_loss: 13.2074 - val_soft_acc: 0.1927\n",
      "Epoch 238/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0787 - soft_acc: 0.1967 - val_loss: 12.2174 - val_soft_acc: 0.2283\n",
      "Epoch 239/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0941 - soft_acc: 0.1934 - val_loss: 12.2331 - val_soft_acc: 0.1953\n",
      "Epoch 240/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1309 - soft_acc: 0.1809 - val_loss: 13.0630 - val_soft_acc: 0.1797\n",
      "Epoch 241/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0841 - soft_acc: 0.1862 - val_loss: 12.5363 - val_soft_acc: 0.2066\n",
      "Epoch 242/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0818 - soft_acc: 0.1914 - val_loss: 13.0754 - val_soft_acc: 0.2101\n",
      "Epoch 243/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2065 - soft_acc: 0.1836 - val_loss: 12.6413 - val_soft_acc: 0.2266\n",
      "Epoch 244/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0501 - soft_acc: 0.2132 - val_loss: 12.2140 - val_soft_acc: 0.1962\n",
      "Epoch 245/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1321 - soft_acc: 0.1901 - val_loss: 12.9390 - val_soft_acc: 0.1936\n",
      "Epoch 246/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0416 - soft_acc: 0.1809 - val_loss: 12.5088 - val_soft_acc: 0.1918\n",
      "Epoch 247/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2524 - soft_acc: 0.1882 - val_loss: 12.3511 - val_soft_acc: 0.1658\n",
      "Epoch 248/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1952 - soft_acc: 0.1789 - val_loss: 12.6618 - val_soft_acc: 0.1319\n",
      "Epoch 249/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0311 - soft_acc: 0.1855 - val_loss: 12.2217 - val_soft_acc: 0.2040\n",
      "Epoch 250/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1694 - soft_acc: 0.1914 - val_loss: 12.3864 - val_soft_acc: 0.2023\n",
      "Epoch 251/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0747 - soft_acc: 0.1921 - val_loss: 12.4967 - val_soft_acc: 0.1953\n",
      "Epoch 252/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0186 - soft_acc: 0.1934 - val_loss: 12.1792 - val_soft_acc: 0.1892\n",
      "Epoch 253/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0641 - soft_acc: 0.2000 - val_loss: 12.4854 - val_soft_acc: 0.1380\n",
      "Epoch 254/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1985 - soft_acc: 0.1941 - val_loss: 12.5217 - val_soft_acc: 0.2049\n",
      "Epoch 255/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0935 - soft_acc: 0.1816 - val_loss: 12.3743 - val_soft_acc: 0.2309\n",
      "Epoch 256/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0205 - soft_acc: 0.1908 - val_loss: 12.5181 - val_soft_acc: 0.2318\n",
      "Epoch 257/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0272 - soft_acc: 0.1934 - val_loss: 12.0785 - val_soft_acc: 0.1901\n",
      "Epoch 258/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1374 - soft_acc: 0.1947 - val_loss: 12.4138 - val_soft_acc: 0.1927\n",
      "Epoch 259/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1824 - soft_acc: 0.1855 - val_loss: 12.4933 - val_soft_acc: 0.2370\n",
      "Epoch 260/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0476 - soft_acc: 0.1901 - val_loss: 12.1870 - val_soft_acc: 0.2109\n",
      "Epoch 261/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0584 - soft_acc: 0.1882 - val_loss: 12.1511 - val_soft_acc: 0.2083\n",
      "Epoch 262/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1946 - soft_acc: 0.1868 - val_loss: 12.7784 - val_soft_acc: 0.2092\n",
      "Epoch 263/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1444 - soft_acc: 0.1862 - val_loss: 12.1262 - val_soft_acc: 0.2161\n",
      "Epoch 264/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0821 - soft_acc: 0.1888 - val_loss: 12.1060 - val_soft_acc: 0.1823\n",
      "Epoch 265/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0430 - soft_acc: 0.1796 - val_loss: 12.1176 - val_soft_acc: 0.2335\n",
      "Epoch 266/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0711 - soft_acc: 0.1888 - val_loss: 12.9346 - val_soft_acc: 0.2127\n",
      "Epoch 267/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1463 - soft_acc: 0.1882 - val_loss: 12.5452 - val_soft_acc: 0.2517\n",
      "Epoch 268/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1631 - soft_acc: 0.1776 - val_loss: 12.1243 - val_soft_acc: 0.2517\n",
      "Epoch 269/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0023 - soft_acc: 0.2033 - val_loss: 12.4522 - val_soft_acc: 0.2413\n",
      "Epoch 270/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1609 - soft_acc: 0.1908 - val_loss: 12.2380 - val_soft_acc: 0.2179\n",
      "Epoch 271/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0089 - soft_acc: 0.1987 - val_loss: 12.0619 - val_soft_acc: 0.2179\n",
      "Epoch 272/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9637 - soft_acc: 0.1941 - val_loss: 12.8725 - val_soft_acc: 0.1979\n",
      "Epoch 273/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1802 - soft_acc: 0.1914 - val_loss: 12.2705 - val_soft_acc: 0.1944\n",
      "Epoch 274/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1397 - soft_acc: 0.1954 - val_loss: 12.1021 - val_soft_acc: 0.1701\n",
      "Epoch 275/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0740 - soft_acc: 0.1954 - val_loss: 12.3778 - val_soft_acc: 0.2491\n",
      "Epoch 276/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0914 - soft_acc: 0.1822 - val_loss: 12.0463 - val_soft_acc: 0.1780\n",
      "Epoch 277/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1119 - soft_acc: 0.1875 - val_loss: 11.9338 - val_soft_acc: 0.1840\n",
      "Epoch 278/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0531 - soft_acc: 0.1875 - val_loss: 12.3660 - val_soft_acc: 0.2066\n",
      "Epoch 279/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9865 - soft_acc: 0.1868 - val_loss: 12.5876 - val_soft_acc: 0.2422\n",
      "Epoch 280/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0359 - soft_acc: 0.1967 - val_loss: 12.6419 - val_soft_acc: 0.2240\n",
      "Epoch 281/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0565 - soft_acc: 0.1908 - val_loss: 12.1022 - val_soft_acc: 0.1806\n",
      "Epoch 282/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2178 - soft_acc: 0.1895 - val_loss: 12.6825 - val_soft_acc: 0.1988\n",
      "Epoch 283/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1814 - soft_acc: 0.1980 - val_loss: 11.9467 - val_soft_acc: 0.2300\n",
      "Epoch 284/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0522 - soft_acc: 0.1974 - val_loss: 12.4175 - val_soft_acc: 0.2066\n",
      "Epoch 285/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1659 - soft_acc: 0.1842 - val_loss: 12.5059 - val_soft_acc: 0.1806\n",
      "Epoch 286/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0393 - soft_acc: 0.2000 - val_loss: 12.2946 - val_soft_acc: 0.2075\n",
      "Epoch 287/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0761 - soft_acc: 0.1882 - val_loss: 12.3347 - val_soft_acc: 0.1988\n",
      "Epoch 288/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0620 - soft_acc: 0.1868 - val_loss: 12.3277 - val_soft_acc: 0.2517\n",
      "Epoch 289/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9931 - soft_acc: 0.1941 - val_loss: 11.9964 - val_soft_acc: 0.2465\n",
      "Epoch 290/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9819 - soft_acc: 0.1816 - val_loss: 12.6550 - val_soft_acc: 0.2431\n",
      "Epoch 291/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0759 - soft_acc: 0.1967 - val_loss: 12.1228 - val_soft_acc: 0.2422\n",
      "Epoch 292/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0955 - soft_acc: 0.1941 - val_loss: 12.4889 - val_soft_acc: 0.2248\n",
      "Epoch 293/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0912 - soft_acc: 0.1921 - val_loss: 12.5070 - val_soft_acc: 0.1832\n",
      "Epoch 294/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.2309 - soft_acc: 0.1928 - val_loss: 12.8015 - val_soft_acc: 0.2118\n",
      "Epoch 295/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0244 - soft_acc: 0.1914 - val_loss: 12.2608 - val_soft_acc: 0.2231\n",
      "Epoch 296/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.1067 - soft_acc: 0.1888 - val_loss: 12.7525 - val_soft_acc: 0.1806\n",
      "Epoch 297/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0515 - soft_acc: 0.1901 - val_loss: 11.8780 - val_soft_acc: 0.1910\n",
      "Epoch 298/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0435 - soft_acc: 0.1993 - val_loss: 11.9245 - val_soft_acc: 0.2066\n",
      "Epoch 299/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9989 - soft_acc: 0.1954 - val_loss: 12.1369 - val_soft_acc: 0.1814\n",
      "Epoch 300/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0991 - soft_acc: 0.1743 - val_loss: 12.1732 - val_soft_acc: 0.2153\n",
      "Epoch 301/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0469 - soft_acc: 0.1947 - val_loss: 12.2201 - val_soft_acc: 0.1684\n",
      "Epoch 302/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9707 - soft_acc: 0.2033 - val_loss: 12.8994 - val_soft_acc: 0.2188\n",
      "Epoch 303/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0283 - soft_acc: 0.1895 - val_loss: 12.7305 - val_soft_acc: 0.2049\n",
      "Epoch 304/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0643 - soft_acc: 0.2000 - val_loss: 12.5207 - val_soft_acc: 0.2648\n",
      "Epoch 305/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0137 - soft_acc: 0.2013 - val_loss: 12.4357 - val_soft_acc: 0.2222\n",
      "Epoch 306/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.1788 - soft_acc: 0.1816 - val_loss: 12.0610 - val_soft_acc: 0.1962\n",
      "Epoch 307/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0368 - soft_acc: 0.1928 - val_loss: 12.1290 - val_soft_acc: 0.2205\n",
      "Epoch 308/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1075 - soft_acc: 0.1928 - val_loss: 12.5310 - val_soft_acc: 0.2422\n",
      "Epoch 309/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9748 - soft_acc: 0.1961 - val_loss: 12.1213 - val_soft_acc: 0.2109\n",
      "Epoch 310/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0652 - soft_acc: 0.1928 - val_loss: 12.2222 - val_soft_acc: 0.2535\n",
      "Epoch 311/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9730 - soft_acc: 0.1974 - val_loss: 12.2343 - val_soft_acc: 0.1997\n",
      "Epoch 312/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0007 - soft_acc: 0.1954 - val_loss: 12.0699 - val_soft_acc: 0.2092\n",
      "Epoch 313/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0580 - soft_acc: 0.1862 - val_loss: 12.0922 - val_soft_acc: 0.1623\n",
      "Epoch 314/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0172 - soft_acc: 0.1954 - val_loss: 12.2722 - val_soft_acc: 0.1814\n",
      "Epoch 315/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0899 - soft_acc: 0.1947 - val_loss: 12.0325 - val_soft_acc: 0.2127\n",
      "Epoch 316/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9924 - soft_acc: 0.1947 - val_loss: 12.2576 - val_soft_acc: 0.2188\n",
      "Epoch 317/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0645 - soft_acc: 0.1967 - val_loss: 12.0104 - val_soft_acc: 0.1884\n",
      "Epoch 318/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.2357 - soft_acc: 0.1882 - val_loss: 12.5028 - val_soft_acc: 0.2205\n",
      "Epoch 319/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9214 - soft_acc: 0.2013 - val_loss: 12.4555 - val_soft_acc: 0.2231\n",
      "Epoch 320/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0723 - soft_acc: 0.2007 - val_loss: 12.4540 - val_soft_acc: 0.2344\n",
      "Epoch 321/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0447 - soft_acc: 0.2033 - val_loss: 12.6798 - val_soft_acc: 0.2483\n",
      "Epoch 322/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9933 - soft_acc: 0.1809 - val_loss: 12.3526 - val_soft_acc: 0.2413\n",
      "Epoch 323/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9642 - soft_acc: 0.2046 - val_loss: 12.6710 - val_soft_acc: 0.2231\n",
      "Epoch 324/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0519 - soft_acc: 0.1941 - val_loss: 12.4428 - val_soft_acc: 0.2179\n",
      "Epoch 325/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1505 - soft_acc: 0.2007 - val_loss: 12.4364 - val_soft_acc: 0.2300\n",
      "Epoch 326/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0627 - soft_acc: 0.1947 - val_loss: 12.1919 - val_soft_acc: 0.2179\n",
      "Epoch 327/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.3697 - soft_acc: 0.1908 - val_loss: 11.9944 - val_soft_acc: 0.1780\n",
      "Epoch 328/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1551 - soft_acc: 0.2007 - val_loss: 13.1685 - val_soft_acc: 0.2335\n",
      "Epoch 329/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9669 - soft_acc: 0.1941 - val_loss: 12.3185 - val_soft_acc: 0.2405\n",
      "Epoch 330/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0456 - soft_acc: 0.2151 - val_loss: 12.0824 - val_soft_acc: 0.2578\n",
      "Epoch 331/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9613 - soft_acc: 0.1974 - val_loss: 12.8398 - val_soft_acc: 0.2526\n",
      "Epoch 332/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9735 - soft_acc: 0.1836 - val_loss: 12.2963 - val_soft_acc: 0.2127\n",
      "Epoch 333/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9862 - soft_acc: 0.2000 - val_loss: 12.0586 - val_soft_acc: 0.2240\n",
      "Epoch 334/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9895 - soft_acc: 0.2000 - val_loss: 12.6631 - val_soft_acc: 0.2483\n",
      "Epoch 335/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0298 - soft_acc: 0.1928 - val_loss: 12.0094 - val_soft_acc: 0.1753\n",
      "Epoch 336/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0466 - soft_acc: 0.1842 - val_loss: 12.2202 - val_soft_acc: 0.2422\n",
      "Epoch 337/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9327 - soft_acc: 0.2013 - val_loss: 12.5714 - val_soft_acc: 0.2153\n",
      "Epoch 338/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0293 - soft_acc: 0.1809 - val_loss: 12.6404 - val_soft_acc: 0.2144\n",
      "Epoch 339/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0898 - soft_acc: 0.1914 - val_loss: 12.0674 - val_soft_acc: 0.1710\n",
      "Epoch 340/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9887 - soft_acc: 0.1934 - val_loss: 11.8575 - val_soft_acc: 0.1962\n",
      "Epoch 341/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9778 - soft_acc: 0.2059 - val_loss: 12.6086 - val_soft_acc: 0.2344\n",
      "Epoch 342/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0338 - soft_acc: 0.2013 - val_loss: 12.3391 - val_soft_acc: 0.2188\n",
      "Epoch 343/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9905 - soft_acc: 0.1947 - val_loss: 12.4384 - val_soft_acc: 0.2769\n",
      "Epoch 344/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9565 - soft_acc: 0.1921 - val_loss: 12.4821 - val_soft_acc: 0.2283\n",
      "Epoch 345/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8837 - soft_acc: 0.2013 - val_loss: 12.5783 - val_soft_acc: 0.2014\n",
      "Epoch 346/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0659 - soft_acc: 0.1974 - val_loss: 11.9761 - val_soft_acc: 0.1962\n",
      "Epoch 347/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9240 - soft_acc: 0.2046 - val_loss: 12.0209 - val_soft_acc: 0.2439\n",
      "Epoch 348/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0523 - soft_acc: 0.1928 - val_loss: 11.9246 - val_soft_acc: 0.2413\n",
      "Epoch 349/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1753 - soft_acc: 0.1875 - val_loss: 12.4733 - val_soft_acc: 0.2405\n",
      "Epoch 350/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9559 - soft_acc: 0.1947 - val_loss: 11.9570 - val_soft_acc: 0.1771\n",
      "Epoch 351/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9523 - soft_acc: 0.1842 - val_loss: 12.1446 - val_soft_acc: 0.1936\n",
      "Epoch 352/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9963 - soft_acc: 0.2013 - val_loss: 11.8743 - val_soft_acc: 0.2153\n",
      "Epoch 353/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9433 - soft_acc: 0.1961 - val_loss: 12.0262 - val_soft_acc: 0.1832\n",
      "Epoch 354/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0620 - soft_acc: 0.1934 - val_loss: 12.2385 - val_soft_acc: 0.2378\n",
      "Epoch 355/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9312 - soft_acc: 0.2033 - val_loss: 12.3877 - val_soft_acc: 0.2188\n",
      "Epoch 356/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.1122 - soft_acc: 0.1947 - val_loss: 12.0663 - val_soft_acc: 0.2474\n",
      "Epoch 357/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9324 - soft_acc: 0.1947 - val_loss: 11.9325 - val_soft_acc: 0.2413\n",
      "Epoch 358/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9733 - soft_acc: 0.1993 - val_loss: 12.1072 - val_soft_acc: 0.2552\n",
      "Epoch 359/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0133 - soft_acc: 0.1868 - val_loss: 11.9835 - val_soft_acc: 0.1649\n",
      "Epoch 360/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9344 - soft_acc: 0.1941 - val_loss: 12.1846 - val_soft_acc: 0.2630\n",
      "Epoch 361/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9978 - soft_acc: 0.1842 - val_loss: 12.2286 - val_soft_acc: 0.2552\n",
      "Epoch 362/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0246 - soft_acc: 0.1954 - val_loss: 12.2647 - val_soft_acc: 0.2153\n",
      "Epoch 363/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9053 - soft_acc: 0.1941 - val_loss: 12.9014 - val_soft_acc: 0.2561\n",
      "Epoch 364/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0058 - soft_acc: 0.2033 - val_loss: 12.3956 - val_soft_acc: 0.2648\n",
      "Epoch 365/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9493 - soft_acc: 0.1901 - val_loss: 12.3878 - val_soft_acc: 0.2465\n",
      "Epoch 366/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0119 - soft_acc: 0.1901 - val_loss: 12.4242 - val_soft_acc: 0.2413\n",
      "Epoch 367/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9439 - soft_acc: 0.1934 - val_loss: 13.1524 - val_soft_acc: 0.2292\n",
      "Epoch 368/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0670 - soft_acc: 0.1987 - val_loss: 12.1379 - val_soft_acc: 0.2405\n",
      "Epoch 369/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9013 - soft_acc: 0.1829 - val_loss: 12.0814 - val_soft_acc: 0.2448\n",
      "Epoch 370/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9501 - soft_acc: 0.1855 - val_loss: 12.4484 - val_soft_acc: 0.2170\n",
      "Epoch 371/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0410 - soft_acc: 0.1822 - val_loss: 12.3342 - val_soft_acc: 0.2457\n",
      "Epoch 372/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0122 - soft_acc: 0.1901 - val_loss: 11.9307 - val_soft_acc: 0.2101\n",
      "Epoch 373/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0774 - soft_acc: 0.1928 - val_loss: 11.9368 - val_soft_acc: 0.2005\n",
      "Epoch 374/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9073 - soft_acc: 0.2000 - val_loss: 12.2313 - val_soft_acc: 0.2361\n",
      "Epoch 375/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.1263 - soft_acc: 0.2099 - val_loss: 12.0825 - val_soft_acc: 0.2049\n",
      "Epoch 376/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9246 - soft_acc: 0.2039 - val_loss: 12.0593 - val_soft_acc: 0.2370\n",
      "Epoch 377/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9278 - soft_acc: 0.1941 - val_loss: 12.4726 - val_soft_acc: 0.2465\n",
      "Epoch 378/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9160 - soft_acc: 0.1967 - val_loss: 12.3139 - val_soft_acc: 0.2604\n",
      "Epoch 379/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9505 - soft_acc: 0.2033 - val_loss: 12.2232 - val_soft_acc: 0.1806\n",
      "Epoch 380/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9287 - soft_acc: 0.1862 - val_loss: 12.3714 - val_soft_acc: 0.2422\n",
      "Epoch 381/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9315 - soft_acc: 0.1849 - val_loss: 12.3964 - val_soft_acc: 0.2144\n",
      "Epoch 382/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8946 - soft_acc: 0.1750 - val_loss: 12.2523 - val_soft_acc: 0.2465\n",
      "Epoch 383/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9492 - soft_acc: 0.1934 - val_loss: 12.2291 - val_soft_acc: 0.2309\n",
      "Epoch 384/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9388 - soft_acc: 0.2046 - val_loss: 12.2403 - val_soft_acc: 0.2222\n",
      "Epoch 385/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0416 - soft_acc: 0.2059 - val_loss: 11.6962 - val_soft_acc: 0.2266\n",
      "Epoch 386/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0961 - soft_acc: 0.1941 - val_loss: 12.4855 - val_soft_acc: 0.1510\n",
      "Epoch 387/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0699 - soft_acc: 0.2046 - val_loss: 12.1427 - val_soft_acc: 0.2092\n",
      "Epoch 388/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0595 - soft_acc: 0.1954 - val_loss: 12.1568 - val_soft_acc: 0.2352\n",
      "Epoch 389/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 9.0219 - soft_acc: 0.1961 - val_loss: 11.7873 - val_soft_acc: 0.2457\n",
      "Epoch 390/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9543 - soft_acc: 0.2046 - val_loss: 12.2290 - val_soft_acc: 0.2205\n",
      "Epoch 391/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9631 - soft_acc: 0.1941 - val_loss: 12.3114 - val_soft_acc: 0.1884\n",
      "Epoch 392/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9270 - soft_acc: 0.1882 - val_loss: 12.1204 - val_soft_acc: 0.2075\n",
      "Epoch 393/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9819 - soft_acc: 0.1967 - val_loss: 12.3278 - val_soft_acc: 0.2153\n",
      "Epoch 394/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0241 - soft_acc: 0.1895 - val_loss: 11.7248 - val_soft_acc: 0.2049\n",
      "Epoch 395/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9964 - soft_acc: 0.1836 - val_loss: 11.9097 - val_soft_acc: 0.2483\n",
      "Epoch 396/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9425 - soft_acc: 0.1967 - val_loss: 12.7088 - val_soft_acc: 0.2561\n",
      "Epoch 397/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8868 - soft_acc: 0.1921 - val_loss: 12.4903 - val_soft_acc: 0.2257\n",
      "Epoch 398/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9620 - soft_acc: 0.1941 - val_loss: 12.2087 - val_soft_acc: 0.2465\n",
      "Epoch 399/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9865 - soft_acc: 0.1868 - val_loss: 12.3816 - val_soft_acc: 0.2153\n",
      "Epoch 400/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0542 - soft_acc: 0.2059 - val_loss: 12.0903 - val_soft_acc: 0.1849\n",
      "Epoch 401/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9013 - soft_acc: 0.1941 - val_loss: 12.2506 - val_soft_acc: 0.2352\n",
      "Epoch 402/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8761 - soft_acc: 0.2039 - val_loss: 11.9865 - val_soft_acc: 0.2361\n",
      "Epoch 403/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9822 - soft_acc: 0.1961 - val_loss: 12.5996 - val_soft_acc: 0.2109\n",
      "Epoch 404/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9511 - soft_acc: 0.1895 - val_loss: 12.1447 - val_soft_acc: 0.2474\n",
      "Epoch 405/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9883 - soft_acc: 0.1961 - val_loss: 12.0148 - val_soft_acc: 0.1762\n",
      "Epoch 406/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9762 - soft_acc: 0.1836 - val_loss: 12.5768 - val_soft_acc: 0.2457\n",
      "Epoch 407/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9026 - soft_acc: 0.1901 - val_loss: 13.0251 - val_soft_acc: 0.2457\n",
      "Epoch 408/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0485 - soft_acc: 0.1954 - val_loss: 12.1700 - val_soft_acc: 0.2517\n",
      "Epoch 409/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9331 - soft_acc: 0.1862 - val_loss: 12.0190 - val_soft_acc: 0.1875\n",
      "Epoch 410/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9644 - soft_acc: 0.1875 - val_loss: 12.0102 - val_soft_acc: 0.2396\n",
      "Epoch 411/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9346 - soft_acc: 0.1987 - val_loss: 12.1707 - val_soft_acc: 0.2274\n",
      "Epoch 412/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8927 - soft_acc: 0.2007 - val_loss: 11.9081 - val_soft_acc: 0.2309\n",
      "Epoch 413/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8132 - soft_acc: 0.1987 - val_loss: 12.1816 - val_soft_acc: 0.2361\n",
      "Epoch 414/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9612 - soft_acc: 0.2105 - val_loss: 12.1766 - val_soft_acc: 0.1510\n",
      "Epoch 415/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9289 - soft_acc: 0.2145 - val_loss: 12.0660 - val_soft_acc: 0.2092\n",
      "Epoch 416/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9407 - soft_acc: 0.1974 - val_loss: 12.8097 - val_soft_acc: 0.2300\n",
      "Epoch 417/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9478 - soft_acc: 0.2086 - val_loss: 12.8703 - val_soft_acc: 0.2057\n",
      "Epoch 418/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9179 - soft_acc: 0.1875 - val_loss: 12.3229 - val_soft_acc: 0.2552\n",
      "Epoch 419/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0252 - soft_acc: 0.1928 - val_loss: 11.8836 - val_soft_acc: 0.2405\n",
      "Epoch 420/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8479 - soft_acc: 0.1993 - val_loss: 12.2777 - val_soft_acc: 0.2491\n",
      "Epoch 421/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9332 - soft_acc: 0.1974 - val_loss: 12.1174 - val_soft_acc: 0.2222\n",
      "Epoch 422/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9255 - soft_acc: 0.2000 - val_loss: 11.8141 - val_soft_acc: 0.2049\n",
      "Epoch 423/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.8584 - soft_acc: 0.1954 - val_loss: 12.5862 - val_soft_acc: 0.1727\n",
      "Epoch 424/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8684 - soft_acc: 0.1980 - val_loss: 11.9543 - val_soft_acc: 0.2344\n",
      "Epoch 425/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8841 - soft_acc: 0.1993 - val_loss: 11.7488 - val_soft_acc: 0.2352\n",
      "Epoch 426/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8798 - soft_acc: 0.2178 - val_loss: 12.2386 - val_soft_acc: 0.2448\n",
      "Epoch 427/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8718 - soft_acc: 0.1934 - val_loss: 12.2768 - val_soft_acc: 0.1979\n",
      "Epoch 428/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9536 - soft_acc: 0.2000 - val_loss: 12.3606 - val_soft_acc: 0.2622\n",
      "Epoch 429/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9042 - soft_acc: 0.1954 - val_loss: 11.8882 - val_soft_acc: 0.2257\n",
      "Epoch 430/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8728 - soft_acc: 0.1987 - val_loss: 12.1845 - val_soft_acc: 0.1589\n",
      "Epoch 431/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9298 - soft_acc: 0.2066 - val_loss: 11.7781 - val_soft_acc: 0.2517\n",
      "Epoch 432/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0093 - soft_acc: 0.1947 - val_loss: 12.1170 - val_soft_acc: 0.2179\n",
      "Epoch 433/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8643 - soft_acc: 0.1961 - val_loss: 12.4164 - val_soft_acc: 0.2569\n",
      "Epoch 434/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9907 - soft_acc: 0.1928 - val_loss: 11.9345 - val_soft_acc: 0.2031\n",
      "Epoch 435/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9329 - soft_acc: 0.1914 - val_loss: 12.8760 - val_soft_acc: 0.2431\n",
      "Epoch 436/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8162 - soft_acc: 0.1901 - val_loss: 11.9362 - val_soft_acc: 0.2352\n",
      "Epoch 437/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7795 - soft_acc: 0.2020 - val_loss: 13.1340 - val_soft_acc: 0.2083\n",
      "Epoch 438/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8880 - soft_acc: 0.1974 - val_loss: 12.7367 - val_soft_acc: 0.2396\n",
      "Epoch 439/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0469 - soft_acc: 0.1849 - val_loss: 12.3942 - val_soft_acc: 0.2309\n",
      "Epoch 440/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8806 - soft_acc: 0.2039 - val_loss: 12.1010 - val_soft_acc: 0.2378\n",
      "Epoch 441/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0241 - soft_acc: 0.2000 - val_loss: 11.8670 - val_soft_acc: 0.2031\n",
      "Epoch 442/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8823 - soft_acc: 0.1961 - val_loss: 12.0413 - val_soft_acc: 0.2135\n",
      "Epoch 443/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8876 - soft_acc: 0.2079 - val_loss: 12.1422 - val_soft_acc: 0.2326\n",
      "Epoch 444/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9959 - soft_acc: 0.2000 - val_loss: 11.8503 - val_soft_acc: 0.2300\n",
      "Epoch 445/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8468 - soft_acc: 0.1974 - val_loss: 12.3593 - val_soft_acc: 0.2422\n",
      "Epoch 446/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9691 - soft_acc: 0.1947 - val_loss: 12.6536 - val_soft_acc: 0.2092\n",
      "Epoch 447/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8249 - soft_acc: 0.2000 - val_loss: 11.9561 - val_soft_acc: 0.2491\n",
      "Epoch 448/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8623 - soft_acc: 0.2039 - val_loss: 12.1353 - val_soft_acc: 0.1944\n",
      "Epoch 449/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9277 - soft_acc: 0.1888 - val_loss: 12.2716 - val_soft_acc: 0.1762\n",
      "Epoch 450/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8193 - soft_acc: 0.1987 - val_loss: 12.1968 - val_soft_acc: 0.2526\n",
      "Epoch 451/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9296 - soft_acc: 0.1921 - val_loss: 12.0380 - val_soft_acc: 0.2378\n",
      "Epoch 452/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8684 - soft_acc: 0.1980 - val_loss: 12.2703 - val_soft_acc: 0.2326\n",
      "Epoch 453/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9131 - soft_acc: 0.1921 - val_loss: 11.9343 - val_soft_acc: 0.1658\n",
      "Epoch 454/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9238 - soft_acc: 0.2026 - val_loss: 12.6603 - val_soft_acc: 0.2439\n",
      "Epoch 455/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8508 - soft_acc: 0.1993 - val_loss: 11.8807 - val_soft_acc: 0.1832\n",
      "Epoch 456/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8432 - soft_acc: 0.2211 - val_loss: 12.1400 - val_soft_acc: 0.2396\n",
      "Epoch 457/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9069 - soft_acc: 0.2046 - val_loss: 12.4349 - val_soft_acc: 0.2535\n",
      "Epoch 458/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8222 - soft_acc: 0.2026 - val_loss: 11.9413 - val_soft_acc: 0.2413\n",
      "Epoch 459/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8847 - soft_acc: 0.2039 - val_loss: 12.2281 - val_soft_acc: 0.2604\n",
      "Epoch 460/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9119 - soft_acc: 0.1954 - val_loss: 12.0128 - val_soft_acc: 0.2101\n",
      "Epoch 461/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8020 - soft_acc: 0.2059 - val_loss: 11.8421 - val_soft_acc: 0.2188\n",
      "Epoch 462/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8720 - soft_acc: 0.1914 - val_loss: 12.6507 - val_soft_acc: 0.2292\n",
      "Epoch 463/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9349 - soft_acc: 0.2007 - val_loss: 11.9325 - val_soft_acc: 0.2266\n",
      "Epoch 464/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8542 - soft_acc: 0.2007 - val_loss: 11.8995 - val_soft_acc: 0.2075\n",
      "Epoch 465/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8514 - soft_acc: 0.2086 - val_loss: 12.1206 - val_soft_acc: 0.2483\n",
      "Epoch 466/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8839 - soft_acc: 0.2020 - val_loss: 12.4951 - val_soft_acc: 0.2448\n",
      "Epoch 467/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9401 - soft_acc: 0.1921 - val_loss: 12.0484 - val_soft_acc: 0.2196\n",
      "Epoch 468/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8014 - soft_acc: 0.1967 - val_loss: 12.1235 - val_soft_acc: 0.1814\n",
      "Epoch 469/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8759 - soft_acc: 0.2020 - val_loss: 12.0958 - val_soft_acc: 0.2127\n",
      "Epoch 470/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9095 - soft_acc: 0.2020 - val_loss: 12.4712 - val_soft_acc: 0.2405\n",
      "Epoch 471/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8330 - soft_acc: 0.2000 - val_loss: 11.7501 - val_soft_acc: 0.2274\n",
      "Epoch 472/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.8463 - soft_acc: 0.2026 - val_loss: 12.1918 - val_soft_acc: 0.2413\n",
      "Epoch 473/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7189 - soft_acc: 0.1987 - val_loss: 11.9300 - val_soft_acc: 0.1979\n",
      "Epoch 474/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.8414 - soft_acc: 0.1954 - val_loss: 12.1882 - val_soft_acc: 0.1632\n",
      "Epoch 475/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9466 - soft_acc: 0.2112 - val_loss: 12.0331 - val_soft_acc: 0.1849\n",
      "Epoch 476/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9528 - soft_acc: 0.1947 - val_loss: 12.1094 - val_soft_acc: 0.1762\n",
      "Epoch 477/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9055 - soft_acc: 0.2046 - val_loss: 12.4574 - val_soft_acc: 0.2422\n",
      "Epoch 478/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.8427 - soft_acc: 0.1987 - val_loss: 11.9932 - val_soft_acc: 0.2387\n",
      "Epoch 479/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8573 - soft_acc: 0.2020 - val_loss: 12.1101 - val_soft_acc: 0.1545\n",
      "Epoch 480/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7782 - soft_acc: 0.2026 - val_loss: 11.8551 - val_soft_acc: 0.1979\n",
      "Epoch 481/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7897 - soft_acc: 0.1993 - val_loss: 12.6274 - val_soft_acc: 0.2561\n",
      "Epoch 482/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7514 - soft_acc: 0.1967 - val_loss: 12.0310 - val_soft_acc: 0.2361\n",
      "Epoch 483/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8818 - soft_acc: 0.2000 - val_loss: 13.7704 - val_soft_acc: 0.2144\n",
      "Epoch 484/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0258 - soft_acc: 0.2079 - val_loss: 13.2815 - val_soft_acc: 0.2222\n",
      "Epoch 485/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9713 - soft_acc: 0.2026 - val_loss: 12.3074 - val_soft_acc: 0.2135\n",
      "Epoch 486/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8827 - soft_acc: 0.2039 - val_loss: 12.0093 - val_soft_acc: 0.2465\n",
      "Epoch 487/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8939 - soft_acc: 0.2066 - val_loss: 12.3840 - val_soft_acc: 0.2439\n",
      "Epoch 488/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8047 - soft_acc: 0.2066 - val_loss: 12.1166 - val_soft_acc: 0.2318\n",
      "Epoch 489/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8557 - soft_acc: 0.1974 - val_loss: 11.9131 - val_soft_acc: 0.2057\n",
      "Epoch 490/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7750 - soft_acc: 0.1928 - val_loss: 12.1066 - val_soft_acc: 0.1840\n",
      "Epoch 491/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9305 - soft_acc: 0.1941 - val_loss: 12.0101 - val_soft_acc: 0.2135\n",
      "Epoch 492/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8104 - soft_acc: 0.1980 - val_loss: 12.0979 - val_soft_acc: 0.2092\n",
      "Epoch 493/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9389 - soft_acc: 0.2079 - val_loss: 11.8875 - val_soft_acc: 0.2188\n",
      "Epoch 494/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7913 - soft_acc: 0.2217 - val_loss: 12.6123 - val_soft_acc: 0.1953\n",
      "Epoch 495/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7720 - soft_acc: 0.2072 - val_loss: 12.3863 - val_soft_acc: 0.2240\n",
      "Epoch 496/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8569 - soft_acc: 0.1868 - val_loss: 12.1114 - val_soft_acc: 0.1875\n",
      "Epoch 497/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7662 - soft_acc: 0.2092 - val_loss: 12.1893 - val_soft_acc: 0.1997\n",
      "Epoch 498/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8004 - soft_acc: 0.2033 - val_loss: 12.2593 - val_soft_acc: 0.2170\n",
      "Epoch 499/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7968 - soft_acc: 0.2059 - val_loss: 12.9589 - val_soft_acc: 0.2370\n",
      "Epoch 500/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8626 - soft_acc: 0.2046 - val_loss: 11.9607 - val_soft_acc: 0.2144\n",
      "Epoch 501/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.9624 - soft_acc: 0.2000 - val_loss: 12.3144 - val_soft_acc: 0.2344\n",
      "Epoch 502/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7847 - soft_acc: 0.2086 - val_loss: 12.0256 - val_soft_acc: 0.2318\n",
      "Epoch 503/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7207 - soft_acc: 0.2013 - val_loss: 12.6523 - val_soft_acc: 0.2214\n",
      "Epoch 504/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8202 - soft_acc: 0.1980 - val_loss: 11.9604 - val_soft_acc: 0.2248\n",
      "Epoch 505/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8712 - soft_acc: 0.1954 - val_loss: 12.4112 - val_soft_acc: 0.2257\n",
      "Epoch 506/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8915 - soft_acc: 0.1934 - val_loss: 12.1040 - val_soft_acc: 0.1814\n",
      "Epoch 507/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8383 - soft_acc: 0.1961 - val_loss: 12.1707 - val_soft_acc: 0.2257\n",
      "Epoch 508/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8705 - soft_acc: 0.2066 - val_loss: 13.0405 - val_soft_acc: 0.2222\n",
      "Epoch 509/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8348 - soft_acc: 0.2033 - val_loss: 12.1441 - val_soft_acc: 0.2474\n",
      "Epoch 510/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8566 - soft_acc: 0.2079 - val_loss: 12.2814 - val_soft_acc: 0.2457\n",
      "Epoch 511/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7891 - soft_acc: 0.2053 - val_loss: 12.3322 - val_soft_acc: 0.2231\n",
      "Epoch 512/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7487 - soft_acc: 0.2020 - val_loss: 12.0295 - val_soft_acc: 0.2266\n",
      "Epoch 513/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8289 - soft_acc: 0.1921 - val_loss: 12.2999 - val_soft_acc: 0.2370\n",
      "Epoch 514/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7753 - soft_acc: 0.1921 - val_loss: 12.0057 - val_soft_acc: 0.2135\n",
      "Epoch 515/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7877 - soft_acc: 0.1888 - val_loss: 11.9912 - val_soft_acc: 0.2309\n",
      "Epoch 516/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7927 - soft_acc: 0.1882 - val_loss: 11.8972 - val_soft_acc: 0.2057\n",
      "Epoch 517/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7725 - soft_acc: 0.2013 - val_loss: 11.9757 - val_soft_acc: 0.2118\n",
      "Epoch 518/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7605 - soft_acc: 0.2046 - val_loss: 12.3201 - val_soft_acc: 0.2326\n",
      "Epoch 519/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8744 - soft_acc: 0.1954 - val_loss: 12.1933 - val_soft_acc: 0.2439\n",
      "Epoch 520/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9256 - soft_acc: 0.2072 - val_loss: 12.0516 - val_soft_acc: 0.2318\n",
      "Epoch 521/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7246 - soft_acc: 0.2020 - val_loss: 11.7969 - val_soft_acc: 0.2240\n",
      "Epoch 522/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8404 - soft_acc: 0.1921 - val_loss: 11.9072 - val_soft_acc: 0.1918\n",
      "Epoch 523/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8043 - soft_acc: 0.2026 - val_loss: 11.8414 - val_soft_acc: 0.1910\n",
      "Epoch 524/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7848 - soft_acc: 0.2138 - val_loss: 11.8725 - val_soft_acc: 0.2179\n",
      "Epoch 525/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8781 - soft_acc: 0.2079 - val_loss: 12.0328 - val_soft_acc: 0.1970\n",
      "Epoch 526/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8574 - soft_acc: 0.2105 - val_loss: 12.0727 - val_soft_acc: 0.1979\n",
      "Epoch 527/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7967 - soft_acc: 0.1914 - val_loss: 12.7536 - val_soft_acc: 0.2335\n",
      "Epoch 528/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7282 - soft_acc: 0.2132 - val_loss: 12.2344 - val_soft_acc: 0.1918\n",
      "Epoch 529/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 9.0726 - soft_acc: 0.1954 - val_loss: 12.1796 - val_soft_acc: 0.1944\n",
      "Epoch 530/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8581 - soft_acc: 0.2039 - val_loss: 12.2266 - val_soft_acc: 0.2326\n",
      "Epoch 531/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7812 - soft_acc: 0.1888 - val_loss: 11.8235 - val_soft_acc: 0.2135\n",
      "Epoch 532/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6437 - soft_acc: 0.2000 - val_loss: 12.2285 - val_soft_acc: 0.2153\n",
      "Epoch 533/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7790 - soft_acc: 0.1947 - val_loss: 12.1029 - val_soft_acc: 0.2318\n",
      "Epoch 534/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9752 - soft_acc: 0.1961 - val_loss: 12.3549 - val_soft_acc: 0.2135\n",
      "Epoch 535/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8376 - soft_acc: 0.1987 - val_loss: 12.4887 - val_soft_acc: 0.2153\n",
      "Epoch 536/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7282 - soft_acc: 0.1947 - val_loss: 11.9673 - val_soft_acc: 0.2075\n",
      "Epoch 537/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7670 - soft_acc: 0.2132 - val_loss: 12.7095 - val_soft_acc: 0.2300\n",
      "Epoch 538/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7619 - soft_acc: 0.1993 - val_loss: 11.9122 - val_soft_acc: 0.2300\n",
      "Epoch 539/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9614 - soft_acc: 0.1987 - val_loss: 12.7586 - val_soft_acc: 0.2387\n",
      "Epoch 540/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7876 - soft_acc: 0.1980 - val_loss: 11.9594 - val_soft_acc: 0.1832\n",
      "Epoch 541/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7096 - soft_acc: 0.2013 - val_loss: 12.0822 - val_soft_acc: 0.2222\n",
      "Epoch 542/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9155 - soft_acc: 0.1901 - val_loss: 12.7920 - val_soft_acc: 0.2214\n",
      "Epoch 543/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7173 - soft_acc: 0.2125 - val_loss: 12.5424 - val_soft_acc: 0.2352\n",
      "Epoch 544/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8105 - soft_acc: 0.1993 - val_loss: 11.8517 - val_soft_acc: 0.1944\n",
      "Epoch 545/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8277 - soft_acc: 0.1987 - val_loss: 12.1958 - val_soft_acc: 0.2014\n",
      "Epoch 546/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9001 - soft_acc: 0.2013 - val_loss: 12.1597 - val_soft_acc: 0.2335\n",
      "Epoch 547/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7234 - soft_acc: 0.2007 - val_loss: 12.0542 - val_soft_acc: 0.2292\n",
      "Epoch 548/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7420 - soft_acc: 0.1928 - val_loss: 12.4354 - val_soft_acc: 0.2378\n",
      "Epoch 549/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7739 - soft_acc: 0.1961 - val_loss: 13.6245 - val_soft_acc: 0.1979\n",
      "Epoch 550/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9200 - soft_acc: 0.2125 - val_loss: 12.7355 - val_soft_acc: 0.2378\n",
      "Epoch 551/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7380 - soft_acc: 0.2020 - val_loss: 12.1599 - val_soft_acc: 0.2396\n",
      "Epoch 552/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8360 - soft_acc: 0.2039 - val_loss: 12.0599 - val_soft_acc: 0.2179\n",
      "Epoch 553/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7231 - soft_acc: 0.2099 - val_loss: 12.0814 - val_soft_acc: 0.2257\n",
      "Epoch 554/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7211 - soft_acc: 0.2053 - val_loss: 12.0852 - val_soft_acc: 0.2283\n",
      "Epoch 555/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7308 - soft_acc: 0.2072 - val_loss: 12.0627 - val_soft_acc: 0.2378\n",
      "Epoch 556/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7477 - soft_acc: 0.2039 - val_loss: 12.3055 - val_soft_acc: 0.2361\n",
      "Epoch 557/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7694 - soft_acc: 0.2086 - val_loss: 12.8054 - val_soft_acc: 0.2248\n",
      "Epoch 558/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7660 - soft_acc: 0.1947 - val_loss: 12.2952 - val_soft_acc: 0.2500\n",
      "Epoch 559/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6873 - soft_acc: 0.2105 - val_loss: 12.2737 - val_soft_acc: 0.2196\n",
      "Epoch 560/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7181 - soft_acc: 0.2000 - val_loss: 11.8727 - val_soft_acc: 0.2127\n",
      "Epoch 561/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7342 - soft_acc: 0.2099 - val_loss: 12.0870 - val_soft_acc: 0.2222\n",
      "Epoch 562/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7722 - soft_acc: 0.2112 - val_loss: 12.0976 - val_soft_acc: 0.2040\n",
      "Epoch 563/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8720 - soft_acc: 0.2026 - val_loss: 12.5132 - val_soft_acc: 0.2335\n",
      "Epoch 564/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7905 - soft_acc: 0.1967 - val_loss: 12.1007 - val_soft_acc: 0.2170\n",
      "Epoch 565/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7268 - soft_acc: 0.1941 - val_loss: 11.9287 - val_soft_acc: 0.1944\n",
      "Epoch 566/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7824 - soft_acc: 0.1934 - val_loss: 12.6066 - val_soft_acc: 0.2405\n",
      "Epoch 567/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7150 - soft_acc: 0.1934 - val_loss: 11.9348 - val_soft_acc: 0.2266\n",
      "Epoch 568/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9052 - soft_acc: 0.1928 - val_loss: 11.7969 - val_soft_acc: 0.2292\n",
      "Epoch 569/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8664 - soft_acc: 0.2053 - val_loss: 11.8858 - val_soft_acc: 0.2448\n",
      "Epoch 570/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6395 - soft_acc: 0.2053 - val_loss: 12.1978 - val_soft_acc: 0.1823\n",
      "Epoch 571/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7855 - soft_acc: 0.1914 - val_loss: 12.3977 - val_soft_acc: 0.2370\n",
      "Epoch 572/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8628 - soft_acc: 0.1954 - val_loss: 12.0362 - val_soft_acc: 0.2274\n",
      "Epoch 573/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9052 - soft_acc: 0.2072 - val_loss: 12.2530 - val_soft_acc: 0.2240\n",
      "Epoch 574/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6895 - soft_acc: 0.1954 - val_loss: 11.9238 - val_soft_acc: 0.2179\n",
      "Epoch 575/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7613 - soft_acc: 0.2066 - val_loss: 12.0028 - val_soft_acc: 0.1918\n",
      "Epoch 576/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7418 - soft_acc: 0.2099 - val_loss: 13.5399 - val_soft_acc: 0.2205\n",
      "Epoch 577/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8659 - soft_acc: 0.2132 - val_loss: 12.2067 - val_soft_acc: 0.2595\n",
      "Epoch 578/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7458 - soft_acc: 0.1967 - val_loss: 12.4086 - val_soft_acc: 0.2517\n",
      "Epoch 579/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7565 - soft_acc: 0.1888 - val_loss: 12.4198 - val_soft_acc: 0.1988\n",
      "Epoch 580/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7061 - soft_acc: 0.2007 - val_loss: 12.0135 - val_soft_acc: 0.2075\n",
      "Epoch 581/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7038 - soft_acc: 0.2053 - val_loss: 12.1658 - val_soft_acc: 0.2083\n",
      "Epoch 582/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9451 - soft_acc: 0.1928 - val_loss: 12.1748 - val_soft_acc: 0.2188\n",
      "Epoch 583/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7117 - soft_acc: 0.1974 - val_loss: 11.8536 - val_soft_acc: 0.2292\n",
      "Epoch 584/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6941 - soft_acc: 0.1934 - val_loss: 12.5152 - val_soft_acc: 0.2127\n",
      "Epoch 585/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7454 - soft_acc: 0.2079 - val_loss: 11.9946 - val_soft_acc: 0.2109\n",
      "Epoch 586/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7089 - soft_acc: 0.2066 - val_loss: 12.1023 - val_soft_acc: 0.2300\n",
      "Epoch 587/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7426 - soft_acc: 0.2046 - val_loss: 12.9532 - val_soft_acc: 0.2335\n",
      "Epoch 588/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.9770 - soft_acc: 0.1914 - val_loss: 12.0211 - val_soft_acc: 0.2023\n",
      "Epoch 589/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8761 - soft_acc: 0.1875 - val_loss: 12.8792 - val_soft_acc: 0.2118\n",
      "Epoch 590/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6944 - soft_acc: 0.1941 - val_loss: 12.1063 - val_soft_acc: 0.2196\n",
      "Epoch 591/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8253 - soft_acc: 0.1967 - val_loss: 12.1527 - val_soft_acc: 0.2274\n",
      "Epoch 592/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6488 - soft_acc: 0.2099 - val_loss: 12.0365 - val_soft_acc: 0.2413\n",
      "Epoch 593/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7338 - soft_acc: 0.2092 - val_loss: 12.4189 - val_soft_acc: 0.2422\n",
      "Epoch 594/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6649 - soft_acc: 0.2112 - val_loss: 12.4232 - val_soft_acc: 0.2309\n",
      "Epoch 595/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7327 - soft_acc: 0.1993 - val_loss: 12.1237 - val_soft_acc: 0.2179\n",
      "Epoch 596/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6075 - soft_acc: 0.2151 - val_loss: 12.3324 - val_soft_acc: 0.2248\n",
      "Epoch 597/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7557 - soft_acc: 0.1934 - val_loss: 11.9552 - val_soft_acc: 0.2170\n",
      "Epoch 598/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8183 - soft_acc: 0.1934 - val_loss: 12.2566 - val_soft_acc: 0.2075\n",
      "Epoch 599/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7502 - soft_acc: 0.1974 - val_loss: 12.7837 - val_soft_acc: 0.2326\n",
      "Epoch 600/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7548 - soft_acc: 0.1855 - val_loss: 11.8175 - val_soft_acc: 0.2326\n",
      "Epoch 601/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8625 - soft_acc: 0.2007 - val_loss: 12.1808 - val_soft_acc: 0.2335\n",
      "Epoch 602/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6436 - soft_acc: 0.1947 - val_loss: 12.1985 - val_soft_acc: 0.2274\n",
      "Epoch 603/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6583 - soft_acc: 0.2178 - val_loss: 12.2818 - val_soft_acc: 0.2352\n",
      "Epoch 604/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6745 - soft_acc: 0.2059 - val_loss: 12.8331 - val_soft_acc: 0.2257\n",
      "Epoch 605/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6763 - soft_acc: 0.2033 - val_loss: 12.5138 - val_soft_acc: 0.2092\n",
      "Epoch 606/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7233 - soft_acc: 0.1908 - val_loss: 12.4054 - val_soft_acc: 0.2031\n",
      "Epoch 607/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7290 - soft_acc: 0.1993 - val_loss: 12.0925 - val_soft_acc: 0.2196\n",
      "Epoch 608/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7791 - soft_acc: 0.2013 - val_loss: 12.9345 - val_soft_acc: 0.2240\n",
      "Epoch 609/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7080 - soft_acc: 0.2086 - val_loss: 11.9577 - val_soft_acc: 0.2005\n",
      "Epoch 610/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6810 - soft_acc: 0.1928 - val_loss: 12.3823 - val_soft_acc: 0.2344\n",
      "Epoch 611/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6972 - soft_acc: 0.1987 - val_loss: 12.1374 - val_soft_acc: 0.2109\n",
      "Epoch 612/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7861 - soft_acc: 0.2072 - val_loss: 12.5251 - val_soft_acc: 0.2370\n",
      "Epoch 613/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7136 - soft_acc: 0.2007 - val_loss: 12.2759 - val_soft_acc: 0.2240\n",
      "Epoch 614/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6466 - soft_acc: 0.2112 - val_loss: 12.1806 - val_soft_acc: 0.2127\n",
      "Epoch 615/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6356 - soft_acc: 0.2039 - val_loss: 12.1097 - val_soft_acc: 0.1849\n",
      "Epoch 616/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7945 - soft_acc: 0.1987 - val_loss: 12.2447 - val_soft_acc: 0.2274\n",
      "Epoch 617/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6127 - soft_acc: 0.2007 - val_loss: 12.3061 - val_soft_acc: 0.2161\n",
      "Epoch 618/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7751 - soft_acc: 0.2007 - val_loss: 12.2174 - val_soft_acc: 0.2101\n",
      "Epoch 619/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7126 - soft_acc: 0.2020 - val_loss: 12.0326 - val_soft_acc: 0.1840\n",
      "Epoch 620/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6667 - soft_acc: 0.1993 - val_loss: 12.3701 - val_soft_acc: 0.2248\n",
      "Epoch 621/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7182 - soft_acc: 0.2026 - val_loss: 12.7390 - val_soft_acc: 0.2361\n",
      "Epoch 622/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6008 - soft_acc: 0.2053 - val_loss: 12.5394 - val_soft_acc: 0.2188\n",
      "Epoch 623/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6569 - soft_acc: 0.1967 - val_loss: 12.8475 - val_soft_acc: 0.2344\n",
      "Epoch 624/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7262 - soft_acc: 0.2053 - val_loss: 12.2503 - val_soft_acc: 0.2222\n",
      "Epoch 625/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6849 - soft_acc: 0.1961 - val_loss: 12.4225 - val_soft_acc: 0.2274\n",
      "Epoch 626/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6947 - soft_acc: 0.2092 - val_loss: 12.1849 - val_soft_acc: 0.2101\n",
      "Epoch 627/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6180 - soft_acc: 0.1914 - val_loss: 11.9872 - val_soft_acc: 0.2083\n",
      "Epoch 628/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7061 - soft_acc: 0.2105 - val_loss: 12.7600 - val_soft_acc: 0.2292\n",
      "Epoch 629/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6789 - soft_acc: 0.2039 - val_loss: 12.3621 - val_soft_acc: 0.2266\n",
      "Epoch 630/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6770 - soft_acc: 0.2026 - val_loss: 11.9946 - val_soft_acc: 0.1936\n",
      "Epoch 631/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6318 - soft_acc: 0.2066 - val_loss: 12.1554 - val_soft_acc: 0.2378\n",
      "Epoch 632/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6674 - soft_acc: 0.2079 - val_loss: 12.0774 - val_soft_acc: 0.2222\n",
      "Epoch 633/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6415 - soft_acc: 0.1974 - val_loss: 12.8680 - val_soft_acc: 0.2326\n",
      "Epoch 634/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7125 - soft_acc: 0.2138 - val_loss: 12.0235 - val_soft_acc: 0.2170\n",
      "Epoch 635/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5733 - soft_acc: 0.2053 - val_loss: 12.4150 - val_soft_acc: 0.2222\n",
      "Epoch 636/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6044 - soft_acc: 0.2013 - val_loss: 12.2539 - val_soft_acc: 0.2248\n",
      "Epoch 637/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6732 - soft_acc: 0.2079 - val_loss: 12.7021 - val_soft_acc: 0.2170\n",
      "Epoch 638/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7401 - soft_acc: 0.1908 - val_loss: 12.0648 - val_soft_acc: 0.1840\n",
      "Epoch 639/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7275 - soft_acc: 0.2059 - val_loss: 12.5165 - val_soft_acc: 0.2248\n",
      "Epoch 640/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7152 - soft_acc: 0.1993 - val_loss: 12.1733 - val_soft_acc: 0.1970\n",
      "Epoch 641/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8396 - soft_acc: 0.1974 - val_loss: 12.6551 - val_soft_acc: 0.2014\n",
      "Epoch 642/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5236 - soft_acc: 0.2013 - val_loss: 12.2169 - val_soft_acc: 0.2109\n",
      "Epoch 643/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8162 - soft_acc: 0.2007 - val_loss: 12.3241 - val_soft_acc: 0.1771\n",
      "Epoch 644/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8093 - soft_acc: 0.1974 - val_loss: 12.3985 - val_soft_acc: 0.2222\n",
      "Epoch 645/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5964 - soft_acc: 0.1974 - val_loss: 13.2791 - val_soft_acc: 0.1997\n",
      "Epoch 646/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7418 - soft_acc: 0.2020 - val_loss: 12.1405 - val_soft_acc: 0.1901\n",
      "Epoch 647/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5292 - soft_acc: 0.2138 - val_loss: 11.8993 - val_soft_acc: 0.2188\n",
      "Epoch 648/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7359 - soft_acc: 0.2059 - val_loss: 13.4070 - val_soft_acc: 0.1884\n",
      "Epoch 649/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7322 - soft_acc: 0.1993 - val_loss: 11.9390 - val_soft_acc: 0.2196\n",
      "Epoch 650/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7554 - soft_acc: 0.2072 - val_loss: 12.0895 - val_soft_acc: 0.2161\n",
      "Epoch 651/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5865 - soft_acc: 0.2020 - val_loss: 11.8850 - val_soft_acc: 0.2144\n",
      "Epoch 652/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7352 - soft_acc: 0.1987 - val_loss: 12.2303 - val_soft_acc: 0.1753\n",
      "Epoch 653/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7391 - soft_acc: 0.1967 - val_loss: 12.3054 - val_soft_acc: 0.1727\n",
      "Epoch 654/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6739 - soft_acc: 0.2138 - val_loss: 12.3855 - val_soft_acc: 0.2248\n",
      "Epoch 655/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6116 - soft_acc: 0.1987 - val_loss: 11.8927 - val_soft_acc: 0.2240\n",
      "Epoch 656/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5479 - soft_acc: 0.1967 - val_loss: 12.1720 - val_soft_acc: 0.2214\n",
      "Epoch 657/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5793 - soft_acc: 0.2086 - val_loss: 12.9875 - val_soft_acc: 0.2075\n",
      "Epoch 658/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7638 - soft_acc: 0.1980 - val_loss: 12.3329 - val_soft_acc: 0.2118\n",
      "Epoch 659/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6802 - soft_acc: 0.1987 - val_loss: 12.1603 - val_soft_acc: 0.1780\n",
      "Epoch 660/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5464 - soft_acc: 0.2125 - val_loss: 12.2945 - val_soft_acc: 0.2205\n",
      "Epoch 661/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6665 - soft_acc: 0.2099 - val_loss: 11.9520 - val_soft_acc: 0.2266\n",
      "Epoch 662/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6709 - soft_acc: 0.1961 - val_loss: 12.2308 - val_soft_acc: 0.2118\n",
      "Epoch 663/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7096 - soft_acc: 0.2112 - val_loss: 12.1575 - val_soft_acc: 0.2222\n",
      "Epoch 664/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5957 - soft_acc: 0.2099 - val_loss: 12.8978 - val_soft_acc: 0.2170\n",
      "Epoch 665/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7243 - soft_acc: 0.1967 - val_loss: 12.8876 - val_soft_acc: 0.1970\n",
      "Epoch 666/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7153 - soft_acc: 0.2033 - val_loss: 12.0822 - val_soft_acc: 0.2049\n",
      "Epoch 667/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6033 - soft_acc: 0.1974 - val_loss: 12.0095 - val_soft_acc: 0.1997\n",
      "Epoch 668/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8694 - soft_acc: 0.2099 - val_loss: 12.6861 - val_soft_acc: 0.2248\n",
      "Epoch 669/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5609 - soft_acc: 0.2053 - val_loss: 12.1170 - val_soft_acc: 0.2196\n",
      "Epoch 670/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6212 - soft_acc: 0.1888 - val_loss: 12.8179 - val_soft_acc: 0.2135\n",
      "Epoch 671/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.6668 - soft_acc: 0.1954 - val_loss: 12.0291 - val_soft_acc: 0.1997\n",
      "Epoch 672/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.6187 - soft_acc: 0.1974 - val_loss: 13.7960 - val_soft_acc: 0.2040\n",
      "Epoch 673/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6820 - soft_acc: 0.2000 - val_loss: 13.1877 - val_soft_acc: 0.2240\n",
      "Epoch 674/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7129 - soft_acc: 0.2046 - val_loss: 12.2902 - val_soft_acc: 0.2057\n",
      "Epoch 675/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6417 - soft_acc: 0.2072 - val_loss: 12.7042 - val_soft_acc: 0.2483\n",
      "Epoch 676/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6486 - soft_acc: 0.1868 - val_loss: 12.0535 - val_soft_acc: 0.1858\n",
      "Epoch 677/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6220 - soft_acc: 0.2059 - val_loss: 13.3588 - val_soft_acc: 0.2170\n",
      "Epoch 678/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6541 - soft_acc: 0.2033 - val_loss: 12.0658 - val_soft_acc: 0.2222\n",
      "Epoch 679/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6684 - soft_acc: 0.2020 - val_loss: 12.3243 - val_soft_acc: 0.2170\n",
      "Epoch 680/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6084 - soft_acc: 0.2066 - val_loss: 12.0938 - val_soft_acc: 0.1840\n",
      "Epoch 681/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6463 - soft_acc: 0.2112 - val_loss: 12.3205 - val_soft_acc: 0.2326\n",
      "Epoch 682/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5736 - soft_acc: 0.1980 - val_loss: 11.9457 - val_soft_acc: 0.2075\n",
      "Epoch 683/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7839 - soft_acc: 0.1993 - val_loss: 12.2410 - val_soft_acc: 0.2352\n",
      "Epoch 684/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5578 - soft_acc: 0.1974 - val_loss: 12.7214 - val_soft_acc: 0.2378\n",
      "Epoch 685/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6578 - soft_acc: 0.1941 - val_loss: 12.8911 - val_soft_acc: 0.2083\n",
      "Epoch 686/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5821 - soft_acc: 0.2079 - val_loss: 12.5562 - val_soft_acc: 0.2118\n",
      "Epoch 687/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5831 - soft_acc: 0.1947 - val_loss: 12.1540 - val_soft_acc: 0.2222\n",
      "Epoch 688/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7762 - soft_acc: 0.2053 - val_loss: 12.8681 - val_soft_acc: 0.2109\n",
      "Epoch 689/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6524 - soft_acc: 0.2092 - val_loss: 12.1311 - val_soft_acc: 0.2257\n",
      "Epoch 690/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6057 - soft_acc: 0.1836 - val_loss: 12.1774 - val_soft_acc: 0.2222\n",
      "Epoch 691/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6025 - soft_acc: 0.2092 - val_loss: 12.4453 - val_soft_acc: 0.2109\n",
      "Epoch 692/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5368 - soft_acc: 0.2013 - val_loss: 12.7580 - val_soft_acc: 0.2222\n",
      "Epoch 693/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6200 - soft_acc: 0.2033 - val_loss: 12.2982 - val_soft_acc: 0.2144\n",
      "Epoch 694/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4751 - soft_acc: 0.1895 - val_loss: 12.5031 - val_soft_acc: 0.2405\n",
      "Epoch 695/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6913 - soft_acc: 0.2033 - val_loss: 12.2905 - val_soft_acc: 0.2405\n",
      "Epoch 696/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6092 - soft_acc: 0.1974 - val_loss: 13.2325 - val_soft_acc: 0.2031\n",
      "Epoch 697/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6177 - soft_acc: 0.1954 - val_loss: 12.4293 - val_soft_acc: 0.1962\n",
      "Epoch 698/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6072 - soft_acc: 0.1974 - val_loss: 12.1825 - val_soft_acc: 0.2240\n",
      "Epoch 699/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7605 - soft_acc: 0.2013 - val_loss: 12.9340 - val_soft_acc: 0.2292\n",
      "Epoch 700/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6009 - soft_acc: 0.2092 - val_loss: 12.0729 - val_soft_acc: 0.1970\n",
      "Epoch 701/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5651 - soft_acc: 0.1895 - val_loss: 12.4738 - val_soft_acc: 0.2118\n",
      "Epoch 702/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6193 - soft_acc: 0.1941 - val_loss: 11.9477 - val_soft_acc: 0.1866\n",
      "Epoch 703/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7578 - soft_acc: 0.2059 - val_loss: 12.5125 - val_soft_acc: 0.2153\n",
      "Epoch 704/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6388 - soft_acc: 0.2092 - val_loss: 12.1950 - val_soft_acc: 0.2335\n",
      "Epoch 705/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6426 - soft_acc: 0.2033 - val_loss: 12.1310 - val_soft_acc: 0.1988\n",
      "Epoch 706/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6360 - soft_acc: 0.2039 - val_loss: 12.1506 - val_soft_acc: 0.2352\n",
      "Epoch 707/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5872 - soft_acc: 0.2039 - val_loss: 11.9011 - val_soft_acc: 0.2118\n",
      "Epoch 708/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6959 - soft_acc: 0.1980 - val_loss: 12.1304 - val_soft_acc: 0.2222\n",
      "Epoch 709/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7383 - soft_acc: 0.1862 - val_loss: 12.6021 - val_soft_acc: 0.2161\n",
      "Epoch 710/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.8220 - soft_acc: 0.1980 - val_loss: 12.3374 - val_soft_acc: 0.2005\n",
      "Epoch 711/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5553 - soft_acc: 0.2086 - val_loss: 13.0314 - val_soft_acc: 0.2161\n",
      "Epoch 712/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5341 - soft_acc: 0.1974 - val_loss: 12.3700 - val_soft_acc: 0.1988\n",
      "Epoch 713/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6556 - soft_acc: 0.2072 - val_loss: 12.5557 - val_soft_acc: 0.1979\n",
      "Epoch 714/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6858 - soft_acc: 0.1954 - val_loss: 12.7502 - val_soft_acc: 0.2057\n",
      "Epoch 715/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5765 - soft_acc: 0.1967 - val_loss: 12.6681 - val_soft_acc: 0.2092\n",
      "Epoch 716/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5969 - soft_acc: 0.1993 - val_loss: 12.4270 - val_soft_acc: 0.2066\n",
      "Epoch 717/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5172 - soft_acc: 0.2224 - val_loss: 12.1561 - val_soft_acc: 0.2066\n",
      "Epoch 718/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5906 - soft_acc: 0.2066 - val_loss: 12.0613 - val_soft_acc: 0.1918\n",
      "Epoch 719/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6692 - soft_acc: 0.2046 - val_loss: 12.6004 - val_soft_acc: 0.2153\n",
      "Epoch 720/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5688 - soft_acc: 0.2020 - val_loss: 13.0318 - val_soft_acc: 0.2109\n",
      "Epoch 721/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5217 - soft_acc: 0.1947 - val_loss: 12.2756 - val_soft_acc: 0.2101\n",
      "Epoch 722/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7913 - soft_acc: 0.1987 - val_loss: 12.7169 - val_soft_acc: 0.2292\n",
      "Epoch 723/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6218 - soft_acc: 0.2033 - val_loss: 12.3533 - val_soft_acc: 0.2170\n",
      "Epoch 724/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5669 - soft_acc: 0.2164 - val_loss: 12.1089 - val_soft_acc: 0.1944\n",
      "Epoch 725/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4753 - soft_acc: 0.2099 - val_loss: 12.4114 - val_soft_acc: 0.2049\n",
      "Epoch 726/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5918 - soft_acc: 0.1993 - val_loss: 12.5876 - val_soft_acc: 0.1988\n",
      "Epoch 727/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4893 - soft_acc: 0.2125 - val_loss: 12.9895 - val_soft_acc: 0.2083\n",
      "Epoch 728/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5532 - soft_acc: 0.2053 - val_loss: 12.0826 - val_soft_acc: 0.2049\n",
      "Epoch 729/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5979 - soft_acc: 0.1849 - val_loss: 12.2848 - val_soft_acc: 0.2127\n",
      "Epoch 730/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5990 - soft_acc: 0.1961 - val_loss: 12.2291 - val_soft_acc: 0.2040\n",
      "Epoch 731/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6778 - soft_acc: 0.1993 - val_loss: 12.3328 - val_soft_acc: 0.2248\n",
      "Epoch 732/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6361 - soft_acc: 0.1993 - val_loss: 12.0962 - val_soft_acc: 0.1892\n",
      "Epoch 733/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.6895 - soft_acc: 0.2105 - val_loss: 12.0260 - val_soft_acc: 0.2109\n",
      "Epoch 734/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5795 - soft_acc: 0.1803 - val_loss: 12.1650 - val_soft_acc: 0.2101\n",
      "Epoch 735/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5648 - soft_acc: 0.2033 - val_loss: 13.0191 - val_soft_acc: 0.2214\n",
      "Epoch 736/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5032 - soft_acc: 0.1961 - val_loss: 12.3338 - val_soft_acc: 0.2170\n",
      "Epoch 737/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4581 - soft_acc: 0.1882 - val_loss: 12.1862 - val_soft_acc: 0.2127\n",
      "Epoch 738/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5176 - soft_acc: 0.1967 - val_loss: 12.9053 - val_soft_acc: 0.2161\n",
      "Epoch 739/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6392 - soft_acc: 0.1947 - val_loss: 12.6925 - val_soft_acc: 0.1866\n",
      "Epoch 740/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5387 - soft_acc: 0.2013 - val_loss: 12.3447 - val_soft_acc: 0.2031\n",
      "Epoch 741/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6270 - soft_acc: 0.1836 - val_loss: 12.0303 - val_soft_acc: 0.2031\n",
      "Epoch 742/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5801 - soft_acc: 0.2112 - val_loss: 12.3782 - val_soft_acc: 0.2118\n",
      "Epoch 743/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4921 - soft_acc: 0.2099 - val_loss: 12.1645 - val_soft_acc: 0.2144\n",
      "Epoch 744/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7185 - soft_acc: 0.1993 - val_loss: 12.6149 - val_soft_acc: 0.2075\n",
      "Epoch 745/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5941 - soft_acc: 0.2039 - val_loss: 12.2563 - val_soft_acc: 0.2092\n",
      "Epoch 746/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6208 - soft_acc: 0.1895 - val_loss: 12.5130 - val_soft_acc: 0.1979\n",
      "Epoch 747/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.7689 - soft_acc: 0.1993 - val_loss: 12.4739 - val_soft_acc: 0.1970\n",
      "Epoch 748/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5888 - soft_acc: 0.2059 - val_loss: 12.0958 - val_soft_acc: 0.1866\n",
      "Epoch 749/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5572 - soft_acc: 0.1980 - val_loss: 12.2251 - val_soft_acc: 0.1910\n",
      "Epoch 750/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5706 - soft_acc: 0.1993 - val_loss: 12.8450 - val_soft_acc: 0.1962\n",
      "Epoch 751/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5596 - soft_acc: 0.2079 - val_loss: 12.8967 - val_soft_acc: 0.2057\n",
      "Epoch 752/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4815 - soft_acc: 0.2118 - val_loss: 13.2417 - val_soft_acc: 0.2283\n",
      "Epoch 753/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5690 - soft_acc: 0.1961 - val_loss: 12.2469 - val_soft_acc: 0.2092\n",
      "Epoch 754/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6590 - soft_acc: 0.1961 - val_loss: 12.2054 - val_soft_acc: 0.2092\n",
      "Epoch 755/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5373 - soft_acc: 0.2066 - val_loss: 12.1216 - val_soft_acc: 0.1953\n",
      "Epoch 756/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5493 - soft_acc: 0.2000 - val_loss: 12.9223 - val_soft_acc: 0.2161\n",
      "Epoch 757/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5197 - soft_acc: 0.2112 - val_loss: 12.0243 - val_soft_acc: 0.2031\n",
      "Epoch 758/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5711 - soft_acc: 0.1974 - val_loss: 12.5794 - val_soft_acc: 0.2274\n",
      "Epoch 759/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4994 - soft_acc: 0.1954 - val_loss: 12.0801 - val_soft_acc: 0.2205\n",
      "Epoch 760/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4793 - soft_acc: 0.2053 - val_loss: 12.3886 - val_soft_acc: 0.2266\n",
      "Epoch 761/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5630 - soft_acc: 0.2125 - val_loss: 11.9839 - val_soft_acc: 0.2118\n",
      "Epoch 762/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4411 - soft_acc: 0.2000 - val_loss: 12.3589 - val_soft_acc: 0.2014\n",
      "Epoch 763/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5563 - soft_acc: 0.2059 - val_loss: 13.6099 - val_soft_acc: 0.2318\n",
      "Epoch 764/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5171 - soft_acc: 0.1967 - val_loss: 12.1495 - val_soft_acc: 0.2205\n",
      "Epoch 765/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5421 - soft_acc: 0.2092 - val_loss: 12.7131 - val_soft_acc: 0.2370\n",
      "Epoch 766/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6549 - soft_acc: 0.1954 - val_loss: 12.3474 - val_soft_acc: 0.1875\n",
      "Epoch 767/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.4715 - soft_acc: 0.2079 - val_loss: 12.4938 - val_soft_acc: 0.2031\n",
      "Epoch 768/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4915 - soft_acc: 0.2026 - val_loss: 12.6886 - val_soft_acc: 0.2188\n",
      "Epoch 769/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6444 - soft_acc: 0.1980 - val_loss: 12.8776 - val_soft_acc: 0.2101\n",
      "Epoch 770/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5117 - soft_acc: 0.2007 - val_loss: 12.3057 - val_soft_acc: 0.1832\n",
      "Epoch 771/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5828 - soft_acc: 0.2099 - val_loss: 12.4682 - val_soft_acc: 0.2161\n",
      "Epoch 772/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5009 - soft_acc: 0.2138 - val_loss: 12.0381 - val_soft_acc: 0.2083\n",
      "Epoch 773/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4861 - soft_acc: 0.2112 - val_loss: 12.1458 - val_soft_acc: 0.2031\n",
      "Epoch 774/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7132 - soft_acc: 0.2079 - val_loss: 12.0550 - val_soft_acc: 0.2127\n",
      "Epoch 775/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6295 - soft_acc: 0.2151 - val_loss: 12.4009 - val_soft_acc: 0.1840\n",
      "Epoch 776/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5722 - soft_acc: 0.2059 - val_loss: 12.2182 - val_soft_acc: 0.2092\n",
      "Epoch 777/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5393 - soft_acc: 0.1974 - val_loss: 12.3685 - val_soft_acc: 0.1997\n",
      "Epoch 778/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.7234 - soft_acc: 0.2020 - val_loss: 12.4844 - val_soft_acc: 0.2240\n",
      "Epoch 779/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.4311 - soft_acc: 0.1934 - val_loss: 12.1329 - val_soft_acc: 0.2135\n",
      "Epoch 780/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.4682 - soft_acc: 0.2072 - val_loss: 12.3212 - val_soft_acc: 0.1892\n",
      "Epoch 781/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.6093 - soft_acc: 0.2191 - val_loss: 12.1891 - val_soft_acc: 0.2040\n",
      "Epoch 782/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4663 - soft_acc: 0.1974 - val_loss: 13.4069 - val_soft_acc: 0.2161\n",
      "Epoch 783/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4349 - soft_acc: 0.2217 - val_loss: 12.8218 - val_soft_acc: 0.1979\n",
      "Epoch 784/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.6848 - soft_acc: 0.1967 - val_loss: 12.2740 - val_soft_acc: 0.2257\n",
      "Epoch 785/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4921 - soft_acc: 0.2112 - val_loss: 12.3383 - val_soft_acc: 0.2387\n",
      "Epoch 786/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4538 - soft_acc: 0.2020 - val_loss: 12.2319 - val_soft_acc: 0.2083\n",
      "Epoch 787/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5413 - soft_acc: 0.2105 - val_loss: 12.3423 - val_soft_acc: 0.2049\n",
      "Epoch 788/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5012 - soft_acc: 0.2099 - val_loss: 12.6721 - val_soft_acc: 0.2101\n",
      "Epoch 789/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5029 - soft_acc: 0.2092 - val_loss: 12.0820 - val_soft_acc: 0.2057\n",
      "Epoch 790/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5394 - soft_acc: 0.1941 - val_loss: 12.6062 - val_soft_acc: 0.2465\n",
      "Epoch 791/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4088 - soft_acc: 0.2191 - val_loss: 12.1953 - val_soft_acc: 0.2127\n",
      "Epoch 792/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4683 - soft_acc: 0.2092 - val_loss: 12.3189 - val_soft_acc: 0.1953\n",
      "Epoch 793/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5835 - soft_acc: 0.1980 - val_loss: 12.9275 - val_soft_acc: 0.2231\n",
      "Epoch 794/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.4829 - soft_acc: 0.1934 - val_loss: 12.2944 - val_soft_acc: 0.2344\n",
      "Epoch 795/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5262 - soft_acc: 0.2039 - val_loss: 12.4692 - val_soft_acc: 0.2222\n",
      "Epoch 796/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.4942 - soft_acc: 0.2033 - val_loss: 12.3612 - val_soft_acc: 0.2005\n",
      "Epoch 797/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.4183 - soft_acc: 0.2151 - val_loss: 12.2765 - val_soft_acc: 0.1745\n",
      "Epoch 798/800\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 8.5054 - soft_acc: 0.2033 - val_loss: 12.8170 - val_soft_acc: 0.2049\n",
      "Epoch 799/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.6219 - soft_acc: 0.2013 - val_loss: 12.5298 - val_soft_acc: 0.1953\n",
      "Epoch 800/800\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 8.5396 - soft_acc: 0.1980 - val_loss: 12.2001 - val_soft_acc: 0.1988\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(8, activation = 'relu', input_dim = 5))\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 7, activation = 'relu'))\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 6, activation = 'relu'))\n",
    "# Adding the third hidden layer\n",
    "model.add(Dense(units = 5, activation = 'relu'))\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the ANN\n",
    "\n",
    "from keras import backend as K\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=[soft_acc])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = model.fit(X_train_ann, y_train, batch_size = 16, epochs = 800, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./withoutUnit/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./withoutUnit/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 8)                 48        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 8)                 48        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5937/5937 [==============================] - 5s 830us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset_2019 = pd.read_csv('dataset_2019.csv')\n",
    "dataset_2019 = dataset_2019[['H', 'W', 'C_x', 'C_y', 'Type of vehicle']]\n",
    "#df = pd.concat([dataset_2018, dataset_2019])\n",
    "df=dataset_2019\n",
    "df['vehicle_dummy']= pd.get_dummies(df['Type of vehicle']).car\n",
    "X = df[['H', 'W', 'C_x', 'C_y',  'Type of vehicle','vehicle_dummy']].values\n",
    "X = np.delete(X, -2, 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "new_model =tf.keras.models.load_model('withoutUnit', compile=False)\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n",
    "df_ann_test= pd.DataFrame(sc.inverse_transform(X), columns=['H', 'W', 'C_x', 'C_y',  'vehicle_dummy'])\n",
    "df_ann_test['predict'] = new_model.predict(X)\n",
    "df_ann_test=df_ann_test.reset_index()\n",
    "dataset_2019 = pd.read_csv('dataset_2019.csv')\n",
    "dataset_2019=dataset_2019.reset_index()\n",
    "dataset_2019=dataset_2019.merge(df_ann_test, on='index')\n",
    "dataset_2019.to_csv('df_ann_test_result_2019_unitless1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189972"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2019 = pd.read_csv('df_ann_test_result_2019_unitless1.csv')\n",
    "dataset_2019=dataset_2019.reset_index(drop=True)\n",
    "len(dataset_2019)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189972"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2019=dataset_2019.merge(df_ann_test, on='index')\n",
    "len(dataset_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>class_ID</th>\n",
       "      <th>H_x</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>W_x</th>\n",
       "      <th>...</th>\n",
       "      <th>refined_dist</th>\n",
       "      <th>phases</th>\n",
       "      <th>spline_dist</th>\n",
       "      <th>Unit</th>\n",
       "      <th>H_y</th>\n",
       "      <th>W_y</th>\n",
       "      <th>C_x_y</th>\n",
       "      <th>C_y_y</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5116</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>477</td>\n",
       "      <td>455</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>77.968696</td>\n",
       "      <td>Following</td>\n",
       "      <td>64.754230</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>466.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>37.863396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5116</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>510</td>\n",
       "      <td>459</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>43.738537</td>\n",
       "      <td>Following</td>\n",
       "      <td>62.584975</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>479.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>17.897783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5117</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>477</td>\n",
       "      <td>457</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>71.731200</td>\n",
       "      <td>Following</td>\n",
       "      <td>60.625697</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>490.5</td>\n",
       "      <td>469.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>35.178840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5117</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>513</td>\n",
       "      <td>459</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>39.850667</td>\n",
       "      <td>Following</td>\n",
       "      <td>58.867743</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>481.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>17.043705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5118</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>477</td>\n",
       "      <td>455</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>71.731200</td>\n",
       "      <td>Following</td>\n",
       "      <td>57.302461</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>490.5</td>\n",
       "      <td>467.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>35.264580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189967</th>\n",
       "      <td>189967</td>\n",
       "      <td>189967</td>\n",
       "      <td>212422</td>\n",
       "      <td>794</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>681</td>\n",
       "      <td>295</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>9.962667</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>11.147102</td>\n",
       "      <td>20</td>\n",
       "      <td>180.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>793.5</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>6.484982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189968</th>\n",
       "      <td>189968</td>\n",
       "      <td>189968</td>\n",
       "      <td>212423</td>\n",
       "      <td>795</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>660</td>\n",
       "      <td>291</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>9.907624</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>10.189844</td>\n",
       "      <td>20</td>\n",
       "      <td>181.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>777.0</td>\n",
       "      <td>381.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>6.671965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189969</th>\n",
       "      <td>189969</td>\n",
       "      <td>189969</td>\n",
       "      <td>212424</td>\n",
       "      <td>798</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>693</td>\n",
       "      <td>275</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>8.747707</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>9.171777</td>\n",
       "      <td>20</td>\n",
       "      <td>205.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>826.5</td>\n",
       "      <td>377.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>6.205824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189970</th>\n",
       "      <td>189970</td>\n",
       "      <td>189970</td>\n",
       "      <td>212425</td>\n",
       "      <td>799</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>690</td>\n",
       "      <td>279</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>8.747707</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>8.091174</td>\n",
       "      <td>20</td>\n",
       "      <td>205.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>823.5</td>\n",
       "      <td>381.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>6.333416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189971</th>\n",
       "      <td>189971</td>\n",
       "      <td>189971</td>\n",
       "      <td>212426</td>\n",
       "      <td>801</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>732</td>\n",
       "      <td>258</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>7.729655</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>6.946309</td>\n",
       "      <td>20</td>\n",
       "      <td>232.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>844.5</td>\n",
       "      <td>374.0</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>5.471088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189972 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   index  Unnamed: 0.1  frame_num  obj_ID  class_ID  H_x  \\\n",
       "0                0       0             0       5116      -1         0   23   \n",
       "1                1       1             1       5116      -1         0   41   \n",
       "2                2       2             2       5117      -1         0   25   \n",
       "3                3       3             3       5117      -1         0   45   \n",
       "4                4       4             4       5118      -1         0   25   \n",
       "...            ...     ...           ...        ...     ...       ...  ...   \n",
       "189967      189967  189967        212422        794      -1         0  180   \n",
       "189968      189968  189968        212423        795      -1         0  181   \n",
       "189969      189969  189969        212424        798      -1         0  205   \n",
       "189970      189970  189970        212425        799      -1         0  205   \n",
       "189971      189971  189971        212426        801      -1         0  232   \n",
       "\n",
       "          L    T  W_x  ...  refined_dist       phases  spline_dist  Unit  \\\n",
       "0       477  455   24  ...     77.968696    Following    64.754230     1   \n",
       "1       510  459   60  ...     43.738537    Following    62.584975     1   \n",
       "2       477  457   27  ...     71.731200    Following    60.625697     1   \n",
       "3       513  459   60  ...     39.850667    Following    58.867743     1   \n",
       "4       477  455   27  ...     71.731200    Following    57.302461     1   \n",
       "...     ...  ...  ...  ...           ...          ...          ...   ...   \n",
       "189967  681  295  225  ...      9.962667  Approaching    11.147102    20   \n",
       "189968  660  291  234  ...      9.907624  Approaching    10.189844    20   \n",
       "189969  693  275  267  ...      8.747707  Approaching     9.171777    20   \n",
       "189970  690  279  267  ...      8.747707  Approaching     8.091174    20   \n",
       "189971  732  258  225  ...      7.729655  Approaching     6.946309    20   \n",
       "\n",
       "          H_y    W_y  C_x_y  C_y_y vehicle_dummy    predict  \n",
       "0        23.0   24.0  489.0  466.5  2.775558e-17  37.863396  \n",
       "1        41.0   60.0  540.0  479.5  2.775558e-17  17.897783  \n",
       "2        25.0   27.0  490.5  469.5  2.775558e-17  35.178840  \n",
       "3        45.0   60.0  543.0  481.5  2.775558e-17  17.043705  \n",
       "4        25.0   27.0  490.5  467.5  2.775558e-17  35.264580  \n",
       "...       ...    ...    ...    ...           ...        ...  \n",
       "189967  180.0  225.0  793.5  385.0  2.775558e-17   6.484982  \n",
       "189968  181.0  234.0  777.0  381.5  2.775558e-17   6.671965  \n",
       "189969  205.0  267.0  826.5  377.5  2.775558e-17   6.205824  \n",
       "189970  205.0  267.0  823.5  381.5  2.775558e-17   6.333416  \n",
       "189971  232.0  225.0  844.5  374.0  2.775558e-17   5.471088  \n",
       "\n",
       "[189972 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/atousaz/Library/CloudStorage/Box-Box/farm/Farm-equipment-following-behaviour\")\n",
    "path='/Users/atousaz/Library/CloudStorage/Box-Box/' \n",
    "df_ann_test_result_2019_unitless=pd.read_csv('df_ann_test_result_2019_unitless.csv')\n",
    "df_ann_test_result_2019_unitless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2020 = pd.read_csv('dataset_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2020 = dataset_2020[['H', 'W', 'C_x', 'C_y',  'Type of vehicle']]\n",
    "#df = pd.concat([dataset_2018, dataset_2019])\n",
    "df=dataset_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['vehicle_dummy']= pd.get_dummies(df['Type of vehicle']).car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['H', 'W', 'C_x', 'C_y',  'Type of vehicle','vehicle_dummy']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, -2, 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 8)                 48        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "new_model =model = tf.keras.models.load_model('withoutUnit', compile=False)\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11866/11866 [==============================] - 10s 808us/step\n"
     ]
    }
   ],
   "source": [
    "df_ann_test= pd.DataFrame(sc.inverse_transform(X), columns=['H', 'W', 'C_x', 'C_y',  'vehicle_dummy'])\n",
    "df_ann_test['predict'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann_test=df_ann_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379705, 379705)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ann_test), len(dataset_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2020 = pd.read_csv('dataset_2020.csv')\n",
    "dataset_2020=dataset_2020.reset_index()\n",
    "dataset_2020=dataset_2020.merge(df_ann_test, on='index')\n",
    "dataset_2020.to_csv('df_ann_test_dataset_2020_unitless.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>class_ID</th>\n",
       "      <th>H_x</th>\n",
       "      <th>L</th>\n",
       "      <th>T</th>\n",
       "      <th>W_x</th>\n",
       "      <th>dist</th>\n",
       "      <th>...</th>\n",
       "      <th>phases</th>\n",
       "      <th>spline_dist</th>\n",
       "      <th>velocity</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>H_y</th>\n",
       "      <th>W_y</th>\n",
       "      <th>C_x_y</th>\n",
       "      <th>C_y_y</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>291</td>\n",
       "      <td>348</td>\n",
       "      <td>30</td>\n",
       "      <td>110.139038</td>\n",
       "      <td>...</td>\n",
       "      <td>Backing off</td>\n",
       "      <td>135.497935</td>\n",
       "      <td>63.230484</td>\n",
       "      <td>-185.776434</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>354.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>46.992714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>288</td>\n",
       "      <td>348</td>\n",
       "      <td>30</td>\n",
       "      <td>110.139038</td>\n",
       "      <td>...</td>\n",
       "      <td>Backing off</td>\n",
       "      <td>137.503749</td>\n",
       "      <td>57.158539</td>\n",
       "      <td>-178.540262</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>354.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>46.934753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>387</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>291</td>\n",
       "      <td>350</td>\n",
       "      <td>30</td>\n",
       "      <td>110.139038</td>\n",
       "      <td>...</td>\n",
       "      <td>Backing off</td>\n",
       "      <td>139.311184</td>\n",
       "      <td>51.327800</td>\n",
       "      <td>-171.304090</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>356.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>46.908516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>390</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>291</td>\n",
       "      <td>352</td>\n",
       "      <td>30</td>\n",
       "      <td>130.164318</td>\n",
       "      <td>...</td>\n",
       "      <td>Backing off</td>\n",
       "      <td>140.928282</td>\n",
       "      <td>45.738266</td>\n",
       "      <td>-164.067919</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>357.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>47.957581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>391</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>291</td>\n",
       "      <td>352</td>\n",
       "      <td>30</td>\n",
       "      <td>110.139038</td>\n",
       "      <td>...</td>\n",
       "      <td>Backing off</td>\n",
       "      <td>142.363082</td>\n",
       "      <td>40.389938</td>\n",
       "      <td>-156.831747</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>358.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>46.824333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379700</th>\n",
       "      <td>379700</td>\n",
       "      <td>582</td>\n",
       "      <td>1626</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>675</td>\n",
       "      <td>336</td>\n",
       "      <td>69</td>\n",
       "      <td>49.372672</td>\n",
       "      <td>...</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>54.758633</td>\n",
       "      <td>-22.426426</td>\n",
       "      <td>176.728000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>709.5</td>\n",
       "      <td>350.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>32.130432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379701</th>\n",
       "      <td>379701</td>\n",
       "      <td>583</td>\n",
       "      <td>1627</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>684</td>\n",
       "      <td>334</td>\n",
       "      <td>72</td>\n",
       "      <td>43.388106</td>\n",
       "      <td>...</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>54.111478</td>\n",
       "      <td>-16.336549</td>\n",
       "      <td>188.664592</td>\n",
       "      <td>33.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>350.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>30.147608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379702</th>\n",
       "      <td>379702</td>\n",
       "      <td>584</td>\n",
       "      <td>1628</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>696</td>\n",
       "      <td>336</td>\n",
       "      <td>72</td>\n",
       "      <td>46.187339</td>\n",
       "      <td>...</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>53.673951</td>\n",
       "      <td>-9.848786</td>\n",
       "      <td>200.601185</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>351.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>31.590725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379703</th>\n",
       "      <td>379703</td>\n",
       "      <td>585</td>\n",
       "      <td>1630</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>714</td>\n",
       "      <td>334</td>\n",
       "      <td>75</td>\n",
       "      <td>43.388106</td>\n",
       "      <td>...</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>53.459313</td>\n",
       "      <td>-2.963137</td>\n",
       "      <td>212.537777</td>\n",
       "      <td>33.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>751.5</td>\n",
       "      <td>350.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>29.050627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379704</th>\n",
       "      <td>379704</td>\n",
       "      <td>586</td>\n",
       "      <td>1631</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>723</td>\n",
       "      <td>332</td>\n",
       "      <td>78</td>\n",
       "      <td>38.697500</td>\n",
       "      <td>...</td>\n",
       "      <td>Approaching</td>\n",
       "      <td>53.480829</td>\n",
       "      <td>4.320399</td>\n",
       "      <td>224.474369</td>\n",
       "      <td>37.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>350.5</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>23.836914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379705 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Unnamed: 0  frame_num  obj_ID  class_ID  H_x    L    T  W_x  \\\n",
       "0            0           0        357      -1         0   13  291  348   30   \n",
       "1            1           1        371      -1         0   13  288  348   30   \n",
       "2            2           2        387      -1         0   13  291  350   30   \n",
       "3            3           3        390      -1         0   11  291  352   30   \n",
       "4            4           4        391      -1         0   13  291  352   30   \n",
       "...        ...         ...        ...     ...       ...  ...  ...  ...  ...   \n",
       "379700  379700         582       1626      -1         0   29  675  336   69   \n",
       "379701  379701         583       1627      -1         0   33  684  334   72   \n",
       "379702  379702         584       1628      -1         0   31  696  336   72   \n",
       "379703  379703         585       1630      -1         0   33  714  334   75   \n",
       "379704  379704         586       1631      -1         0   37  723  332   78   \n",
       "\n",
       "              dist  ...       phases  spline_dist   velocity acceleration  \\\n",
       "0       110.139038  ...  Backing off   135.497935  63.230484  -185.776434   \n",
       "1       110.139038  ...  Backing off   137.503749  57.158539  -178.540262   \n",
       "2       110.139038  ...  Backing off   139.311184  51.327800  -171.304090   \n",
       "3       130.164318  ...  Backing off   140.928282  45.738266  -164.067919   \n",
       "4       110.139038  ...  Backing off   142.363082  40.389938  -156.831747   \n",
       "...            ...  ...          ...          ...        ...          ...   \n",
       "379700   49.372672  ...  Approaching    54.758633 -22.426426   176.728000   \n",
       "379701   43.388106  ...  Approaching    54.111478 -16.336549   188.664592   \n",
       "379702   46.187339  ...  Approaching    53.673951  -9.848786   200.601185   \n",
       "379703   43.388106  ...  Approaching    53.459313  -2.963137   212.537777   \n",
       "379704   38.697500  ...  Approaching    53.480829   4.320399   224.474369   \n",
       "\n",
       "         H_y   W_y  C_x_y  C_y_y vehicle_dummy    predict  \n",
       "0       13.0  30.0  306.0  354.5  2.775558e-17  46.992714  \n",
       "1       13.0  30.0  303.0  354.5  2.775558e-17  46.934753  \n",
       "2       13.0  30.0  306.0  356.5  2.775558e-17  46.908516  \n",
       "3       11.0  30.0  306.0  357.5  2.775558e-17  47.957581  \n",
       "4       13.0  30.0  306.0  358.5  2.775558e-17  46.824333  \n",
       "...      ...   ...    ...    ...           ...        ...  \n",
       "379700  29.0  69.0  709.5  350.5  2.775558e-17  32.130432  \n",
       "379701  33.0  72.0  720.0  350.5  2.775558e-17  30.147608  \n",
       "379702  31.0  72.0  732.0  351.5  2.775558e-17  31.590725  \n",
       "379703  33.0  75.0  751.5  350.5  2.775558e-17  29.050627  \n",
       "379704  37.0  78.0  762.0  350.5  2.775558e-17  23.836914  \n",
       "\n",
       "[379705 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 8)                 48        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 63        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 6)                 48        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "8676/8676 [==============================] - 7s 782us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset_2018 = pd.read_csv('dataset_2018.csv')\n",
    "dataset_2018 = dataset_2018[['H', 'W', 'C_x', 'C_y', 'Type of vehicle']]\n",
    "#df = pd.concat([dataset_2018, dataset_2019])\n",
    "df=dataset_2018\n",
    "df['vehicle_dummy']= pd.get_dummies(df['Type of vehicle']).car\n",
    "X = df[['H', 'W', 'C_x', 'C_y',  'Type of vehicle','vehicle_dummy']].values\n",
    "X = np.delete(X, -2, 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "new_model =tf.keras.models.load_model('withoutUnit', compile=False)\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n",
    "df_ann_test= pd.DataFrame(sc.inverse_transform(X), columns=['H', 'W', 'C_x', 'C_y',  'vehicle_dummy'])\n",
    "df_ann_test['predict'] = model.predict(X)\n",
    "df_ann_test=df_ann_test.reset_index()\n",
    "dataset_2018 = pd.read_csv('dataset_2018.csv')\n",
    "dataset_2018=dataset_2018.reset_index()\n",
    "dataset_2018=dataset_2018.merge(df_ann_test, on='index')\n",
    "dataset_2018.to_csv('df_ann_test_result_2018_unitless1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2018 = pd.read_csv('df_ann_test_result_2018_unitless1.csv')\n",
    "dataset_2018=dataset_2018.reset_index()\n",
    "len(dataset_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2018=dataset_2018.merge(df_ann_test, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189789"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "\n",
      "unit:  28.0\n",
      "mean:  -0.7722046848283918 std:  3.6034686840573174\n",
      "\n",
      "unit:  45.0\n",
      "mean:  -0.20603791446342729 std:  1.1509137767062045\n",
      "\n",
      "unit:  60.0\n",
      "mean:  -0.015982219054372904 std:  1.6817443312539468\n",
      "\n",
      "unit:  79.5\n",
      "mean:  -0.4181351168987536 std:  3.6563985044094864\n",
      "\n",
      "1.0\n",
      "\n",
      "unit:  28.0\n",
      "mean:  0.3843684862026622 std:  3.3966856295115377\n",
      "\n",
      "unit:  45.0\n",
      "mean:  0.5582762519299376 std:  2.825417030900864\n",
      "\n",
      "unit:  60.0\n",
      "mean:  -1.2448268921346903 std:  2.3905181008646537\n",
      "\n",
      "unit:  79.5\n",
      "mean:  0.12418164930546141 std:  4.519807885187755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "for n , g in df_ann_test.groupby('vehicle_dummy'): \n",
    "    print(n)\n",
    "    if n == 0:\n",
    "        n = 'truck'\n",
    "    else:\n",
    "        n = 'car'\n",
    "    print('')\n",
    "    for name, group in g.groupby('unit'):\n",
    "        res =  group.predict - group.gps_dist\n",
    "        print('unit: ', name)\n",
    "        print('mean: ', np.mean(res),'std: ', np.std(res))\n",
    "        print('')\n",
    "        r.append([np.mean(res), np.std(res), name, 'ann', n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(r,columns=['mean','std','unit','model','vehicle'])\n",
    "df_result = pd.concat([df_result,r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinhole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_cal_by_model(x, y):\n",
    "    if y == 'car':\n",
    "        return 851 * 1.445 / x\n",
    "    else: #for pickup truck\n",
    "        return 934 * 1.920 / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pin_test = pd.DataFrame(X_test, columns=['H', 'W', 'C_x', 'C_y', 'unit', 'vehicle','vehicle_dummy'])\n",
    "df_pin_test['gps_dist'] = y_test\n",
    "df_pin_test['predict'] = np.vectorize(dist_cal_by_model)(df_pin_test['H'], df_pin_test['vehicle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "\n",
      "unit:  28.0\n",
      "mean:  -7.814054927644907 std:  3.4813983970937965\n",
      "\n",
      "unit:  45.0\n",
      "mean:  1.0552302014618276 std:  4.6893603309609295\n",
      "\n",
      "unit:  60.0\n",
      "mean:  0.5221440413565003 std:  2.9132852672291616\n",
      "\n",
      "unit:  79.5\n",
      "mean:  1.9966328623779288 std:  6.0746761913159455\n",
      "\n",
      "truck\n",
      "\n",
      "unit:  28.0\n",
      "mean:  -0.2927863968211002 std:  4.561209335681658\n",
      "\n",
      "unit:  45.0\n",
      "mean:  0.9677752937623209 std:  1.5407142693237292\n",
      "\n",
      "unit:  60.0\n",
      "mean:  0.7395593826965754 std:  1.4144145853773102\n",
      "\n",
      "unit:  79.5\n",
      "mean:  -0.04764107678125455 std:  4.652909010307651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "for n , g in df_pin_test.groupby('vehicle'): \n",
    "    print(n)\n",
    "    print('')\n",
    "    for name, group in g.groupby('unit'):\n",
    "        res =  group.predict - group.gps_dist\n",
    "        print('unit: ', name)\n",
    "        print('mean: ', np.mean(res),'std: ', np.std(res))\n",
    "        print('')\n",
    "        r.append([np.mean(res), np.std(res), name, 'pin', n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(r,columns=['mean','std','unit','model', 'vehicle'])\n",
    "df_result = pd.concat([df_result,r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_car = df_result[df_result.vehicle == 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>unit</th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001409</td>\n",
       "      <td>5.507082</td>\n",
       "      <td>28.0</td>\n",
       "      <td>reg</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987677</td>\n",
       "      <td>7.106748</td>\n",
       "      <td>45.0</td>\n",
       "      <td>reg</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.625197</td>\n",
       "      <td>8.905477</td>\n",
       "      <td>60.0</td>\n",
       "      <td>reg</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.297796</td>\n",
       "      <td>8.917542</td>\n",
       "      <td>79.5</td>\n",
       "      <td>reg</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.772205</td>\n",
       "      <td>3.603469</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ann</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.206038</td>\n",
       "      <td>1.150914</td>\n",
       "      <td>45.0</td>\n",
       "      <td>ann</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.015982</td>\n",
       "      <td>1.681744</td>\n",
       "      <td>60.0</td>\n",
       "      <td>ann</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.418135</td>\n",
       "      <td>3.656399</td>\n",
       "      <td>79.5</td>\n",
       "      <td>ann</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.292786</td>\n",
       "      <td>4.561209</td>\n",
       "      <td>28.0</td>\n",
       "      <td>pin</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.967775</td>\n",
       "      <td>1.540714</td>\n",
       "      <td>45.0</td>\n",
       "      <td>pin</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.739559</td>\n",
       "      <td>1.414415</td>\n",
       "      <td>60.0</td>\n",
       "      <td>pin</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.047641</td>\n",
       "      <td>4.652909</td>\n",
       "      <td>79.5</td>\n",
       "      <td>pin</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean       std  unit model vehicle\n",
       "0  -0.001409  5.507082  28.0   reg   truck\n",
       "1   0.987677  7.106748  45.0   reg   truck\n",
       "2  -0.625197  8.905477  60.0   reg   truck\n",
       "3  -1.297796  8.917542  79.5   reg   truck\n",
       "4  -0.772205  3.603469  28.0   ann   truck\n",
       "5  -0.206038  1.150914  45.0   ann   truck\n",
       "6  -0.015982  1.681744  60.0   ann   truck\n",
       "7  -0.418135  3.656399  79.5   ann   truck\n",
       "8  -0.292786  4.561209  28.0   pin   truck\n",
       "9   0.967775  1.540714  45.0   pin   truck\n",
       "10  0.739559  1.414415  60.0   pin   truck\n",
       "11 -0.047641  4.652909  79.5   pin   truck"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_car.reset_index(drop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00140943,  0.98767733, -0.62519653, -1.29779606, -0.77220468,\n",
       "       -0.20603791, -0.01598222, -0.41813512, -0.2927864 ,  0.96777529,\n",
       "        0.73955938, -0.04764108])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_car.columns = ['mean_1', 'std_1', 'unit', 'model', 'vehicle']\n",
    "df_car['mean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car['mean'] = [-1.40942776e-03,  9.87677334e-01, -6.25196531e-01, -1.29779606e+00,\n",
    "        3.53865312e-01,  2.29753753e-01, -1.19600906e+00, -7.06992966e-02,\n",
    "       .4342,  1.05523020e+00,  5.22144041e-01,  1.99663286e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car['unit_m'] = df_car.unit * 0.0254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-15., -10.,  -5.,   0.,   5.,  10.,  15.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4.5,4.5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_xlabel('Camera height (m)', fontsize=12, style = 'italic', weight='bold')\n",
    "ax1.set_ylabel('Erorr (m)', fontsize=12,style = 'italic', weight='bold')\n",
    "trans1 = ax1.transData + ScaledTranslation(-5/72, 0, fig.dpi_scale_trans)\n",
    "trans2 = ax1.transData + ScaledTranslation(0, 0, fig.dpi_scale_trans)\n",
    "trans3 = ax1.transData + ScaledTranslation(+5/72, 0, fig.dpi_scale_trans)\n",
    "ax1.set_xlim([0.6,2.1])\n",
    "ax1.set_ylim([-15,15])\n",
    "ax1.errorbar(df_car[df_car.model == 'reg'].unit_m.values, df_car[df_car.model == 'reg']['mean'].values,\n",
    "             yerr=df_car[df_car.model == 'reg']['std'].values,marker=\"o\", linestyle=\"none\", transform = trans1,\n",
    "            label = 'Regression')\n",
    "ax1.errorbar(df_car[df_car.model == 'pin'].unit_m.values, df_car[df_car.model == 'pin']['mean'].values ,\n",
    "             yerr=df_car[df_car.model == 'pin']['std'].values,marker=\"^\", linestyle=\"none\", transform = trans2,\n",
    "            label = 'Pinhole')\n",
    "ax1.errorbar(df_car[df_car.model == 'ann'].unit_m.values, df_car[df_car.model == 'ann']['mean'].values,\n",
    "             yerr=df_car[df_car.model == 'ann']['std'].values,marker=\"v\", linestyle=\"none\", transform = trans3,\n",
    "            label = 'ANN')\n",
    "ax1.legend(loc='best', scatterpoints = 1, fontsize=8)\n",
    "ax1.axhline(ls = '--', alpha = .2, c='k')\n",
    "ax1.set_xticks(np.round(df_car.unit_m.values,2))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.savefig('errorbar_truck.pdf',dpi=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/saeedarabi/Downloads\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['soft_acc'])\n",
    "plt.plot(history.history['val_soft_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(np.log(history.history['loss']))\n",
    "plt.plot(np.log(history.history['val_loss']))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>C_x</th>\n",
       "      <th>C_y</th>\n",
       "      <th>unit</th>\n",
       "      <th>vehicle_dummy</th>\n",
       "      <th>gps_dist</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>420.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.382472</td>\n",
       "      <td>11.134441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.947480</td>\n",
       "      <td>10.421755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.683308</td>\n",
       "      <td>20.302671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>382.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.909683</td>\n",
       "      <td>37.129906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.373707</td>\n",
       "      <td>45.295811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>426.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.604501</td>\n",
       "      <td>40.996113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>428.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.947317</td>\n",
       "      <td>36.435474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.540706</td>\n",
       "      <td>33.804893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.512966</td>\n",
       "      <td>33.870205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.601233</td>\n",
       "      <td>34.288799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         H      W    C_x    C_y  unit  vehicle_dummy   gps_dist    predict\n",
       "0    121.0  166.0  385.0  420.5  45.0            1.0  15.382472  11.134441\n",
       "1    180.0  204.0  390.0  471.0  28.0            1.0  15.947480  10.421755\n",
       "2     60.0   78.0  483.0  442.0  60.0            1.0  22.683308  20.302671\n",
       "3     45.0   50.0  429.0  382.5  45.0            0.0  36.909683  37.129906\n",
       "4     26.0   40.0  516.0  425.0  60.0            1.0  43.373707  45.295811\n",
       "..     ...    ...    ...    ...   ...            ...        ...        ...\n",
       "470   39.0   44.0  504.0  426.5  28.0            1.0  42.604501  40.996113\n",
       "471   47.0   50.0  507.0  428.5  28.0            0.0  35.947317  36.435474\n",
       "472   52.0   56.0  430.0  386.0  45.0            0.0  33.540706  33.804893\n",
       "473   50.0   56.0  518.0  430.0  60.0            0.0  33.512966  33.870205\n",
       "474   52.0   60.0  540.0  431.0  79.5            0.0  34.601233  34.288799\n",
       "\n",
       "[475 rows x 8 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ann_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Residual (m)')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp_car = df_ann_test[(df_ann_test.vehicle_dummy == 0) & (df_ann_test.unit == 45)] # 0:truck, 1:car\n",
    "fig = plt.figure(figsize=(6.5,3.5))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(df_tmp_car.gps_dist, df_tmp_car.predict - df_tmp_car.gps_dist, alpha=.5, facecolors='none', edgecolors='k')\n",
    "ax1.set_xlim([0,90])\n",
    "ax1.set_ylim([-5,5])\n",
    "ax1.axhline(ls = '--', alpha = .2, c='k')\n",
    "dft = df_tmp_car[(df_tmp_car.gps_dist<10) & (df_tmp_car.gps_dist>0)]\n",
    "ax1.set_xlabel('Distance (m)', fontsize=8, style = 'italic', weight='bold')\n",
    "ax1.set_ylabel('Residual (m)', fontsize=8,style = 'italic', weight='bold')\n",
    "# plt.savefig('residuals_truck.pdf',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, group in df_tmp_car.groupby('unit'):\n",
    "    print(name)\n",
    "    fig = plt.figure(figsize=(3.5,3.5))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.hist(group.predict - group.gps_dist)\n",
    "    ax1.set_xlabel('Residual (m)', fontsize=8, style = 'italic', weight='bold')\n",
    "    ax1.set_ylabel('Frequency', fontsize=8,style = 'italic', weight='bold')\n",
    "    plt.savefig('dist_truck_{}.pdf'.format(name),dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    val = x['y_pred'] - x['y_test']\n",
    "    return pd.Series([np.mean(val), np.std(val), iqr(val)]).reset_index(drop = True)\n",
    "\n",
    "df = pd.DataFrame(sc.inverse_transform(X_test), columns=['H', 'W', 'C_x', 'C_y', 'unit', 'vehicle'])\n",
    "df['y_pred'] = y_pred\n",
    "df['y_test'] = y_test\n",
    "df = df[df['vehicle'] == 0]\n",
    "\n",
    "# df = df.groupby('unit')\n",
    "\n",
    "df = df.groupby('unit').apply(f).reset_index()\n",
    "df.columns = ['unit_h', 'deep model mean', 'deep model std','deep model iqr' ]\n",
    "df['unit_name'] = [ \"Unit 13 \\n (0.71)\", \"Unit 10 \\n (1.14 m)\", \"Unit 12 \\n (1.52)\", \"Unit 17 \\n (2 m)\"]\n",
    "df.index = df['unit_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df:\n",
    "    print(name)\n",
    "    plt.figure()\n",
    "    plt.hist(group.y_pred - group.y_test)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['truck_mean'] = df_truck.mean().values\n",
    "df['truck_std'] = df_truck.std()\n",
    "df['truck_iqr'] = iqr(df_truck, axis = 0)\n",
    "df['car_mean'] = df_car.mean()\n",
    "df['car_std'] = df_car.std()\n",
    "df['car_iqr'] = iqr(df_car, axis = 0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_truck = [-0.2492995561347824]\n",
    "std_truck = [2.70862288681874]\n",
    "std_car = [3.7408812882449993]\n",
    "mean_car = [-0.12542908901759484]\n",
    "print([df_truck.values.mean(), df_car.dropna().values.mean()])\n",
    "print([df_truck.values.std(), df_car.dropna().values.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['unit_h', 'deep model mean', 'deep model std', 'deep model iqr',\n",
    "        'truck_mean', 'truck_std', 'truck_iqr', 'car_mean',\n",
    "       'car_std', 'car_iqr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,15))\n",
    "df[['deep model mean', 'truck_mean']].plot(kind='bar', yerr=df[['deep model std', 'truck_std']].values.T, xlabel='unit', ylabel='error (m)', figsize=(10,5)) \n",
    "plt.legend([\"Deep model\", 'Pinhole model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.mean().plot(legend=False,kind=\"bar\",\n",
    "                          color=\"red\",rot=0,fontsize=16,yerr=df.std(), figsize=(6.5,6.5))\n",
    "font = font_manager.FontProperties(family = fontname, style='italic', size=14)\n",
    "plt.xticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.yticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.xlabel('Units', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "plt.ylabel('Distance Error (m)', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "ax.set_ylim((-5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.scatter(range(len(y_test)), y_test, color = 'red', label = 'Real data')\n",
    "plt.scatter(range(len(y_pred)), y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.scatter(range(len(y_pred)), (y_test - y_pred), color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(y_test - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_test - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr(y_test - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x=y_test.reshape(713,1), y=(y_pred.reshape(713,1) - y_test.reshape(713,1)), alpha=.2, facecolors='none', edgecolors='r')\n",
    "# plt.gca().update(dict(xlabel='y_test', ylabel='residuals (y_pred - y_test)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(x=y_test.reshape(713,1), y=(y_pred.reshape(713,1) - y_test.reshape(713,1)), alpha=.2, facecolors='none', edgecolors='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"Unit 13 \\n (0.71)\", \"Unit 10 \\n (1.14 m)\", \"Unit 12 \\n (1.52)\", \"Unit 17 \\n (2 m)\"]\n",
    "truck = [[0.056918, 0.265463, 0.213490, -0.082971],\n",
    "[0.271355, 1.127730, 1.28477, 1.969870],\n",
    "[0.392258, 0.318478, -0.042042, 0.520576],\n",
    "[0.744019, 1.485808, 1.618756, 0.043278],\n",
    "[ -0.013213, -0.249351, -0.274474, -0.067475],\n",
    "[0.629137, 0.425123, 0.254424, 0.642990],\n",
    "[0.204234, 0.661938, 0.512799, -0.007783],\n",
    "[0.238437, 0.194066, -0.161833, -0.180112]]\n",
    "df_truck = pd.DataFrame(truck, columns=columns)\n",
    "\n",
    "ax = df_truck.mean().plot(legend=False,kind=\"bar\",\n",
    "                          color=\"red\",rot=0,fontsize=16,yerr=df_truck.std(), figsize=(6.5,6.5))\n",
    "font = font_manager.FontProperties(family = fontname, style='italic', size=14)\n",
    "plt.xticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.yticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.xlabel('Units', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "plt.ylabel('Distance Error (m)', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "ax.set_ylim((-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truck.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truck.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ \"Unit 13 \\n (0.71)\", \"Unit 10 \\n (1.14 m)\", \"Unit 12 \\n (1.52)\", \"Unit 17 \\n (2 m)\"]\n",
    "car = [[-0.142094, -0.052965, 0.157796, 0.289925],\n",
    "[-0.954387, -1.601214, 3.888085, -0.012008],\n",
    "[0.926389, 2.075867, -0.298162, -1.160564], \n",
    "[3.827156, 1.483507, -0.245916, -0.611535], \n",
    "[-1.718267, 0.712902, 0.575612, 0.341381],\n",
    "[np.nan, -0.944339, -0.768733, -1.230775],\n",
    "[0.859783, 1.272305, -0.411629, 0.732448],\n",
    "[1.329752, -0.407789, np.nan , 1.783246]]\n",
    "df_car = pd.DataFrame(car, columns=columns)\n",
    "df_car.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_car.mean().plot(legend=False,kind=\"bar\",\n",
    "                          color=\"red\",rot=0,fontsize=10,yerr=df_car.std(), figsize=(6.5,6.5))\n",
    "font = font_manager.FontProperties(family = fontname, style='italic', size=14)\n",
    "plt.xticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.yticks(weight = 'bold', style = 'italic', fontname = fontname, fontsize=14)\n",
    "plt.xlabel('Units', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "plt.ylabel('Distance Error (m)', fontsize=16,style = 'italic', weight='bold', fontname=fontname)\n",
    "ax.set_ylim((-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
